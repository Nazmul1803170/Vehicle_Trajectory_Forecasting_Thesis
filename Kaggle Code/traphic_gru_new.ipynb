{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8190586,"sourceType":"datasetVersion","datasetId":4850427}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install klepto","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T05:35:56.107519Z","iopub.execute_input":"2024-04-22T05:35:56.107942Z","iopub.status.idle":"2024-04-22T05:36:08.463880Z","shell.execute_reply.started":"2024-04-22T05:35:56.107910Z","shell.execute_reply":"2024-04-22T05:36:08.462613Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: klepto in /opt/conda/lib/python3.10/site-packages (0.2.5)\nRequirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from klepto) (0.3.4)\nRequirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from klepto) (0.3.8)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# file_path = '/path/to/your/file.txt'\nfile_path = '/kaggle/input/apoldata/data'\n\n\nif os.path.exists(file_path):\n    print(\"File exists!\")\nelse:\n    print(\"File does not exist.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.465973Z","iopub.execute_input":"2024-04-22T05:36:08.466325Z","iopub.status.idle":"2024-04-22T05:36:08.473255Z","shell.execute_reply.started":"2024-04-22T05:36:08.466288Z","shell.execute_reply":"2024-04-22T05:36:08.472350Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"File exists!\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction/util.py\n# -*- coding: utf-8 -*-\nfrom __future__ import print_function, division\nfrom torch.utils.data import Dataset, DataLoader\nimport scipy.io as scp\nimport numpy as np\nimport torch\nimport pickle\nimport os\nfrom klepto.archives import dir_archive\n\n#___________________________________________________________________________________________________________________________\n\ndef lstToCuda(lst):\n    for item in lst:\n        item.cuda()\n    return lst\n\ndef klepto_load(loc):\n    '''\n    for loading the dumped dictionarys\n    :return: loaded dictionary\n    '''\n\n    dic = dir_archive(loc, {}, serialized=True)\n    dic.load()\n    print('dictionary loaded')\n    return dic\n\n### Dataset class for the NGSIM dataset\nclass ngsimDataset(Dataset):\n\n    '''\n    t_h = input size (history)\n    t_f = output size (future)\n    '''\n    def __init__(self, file_name, data_dir, track_dir, dtype, dsId, class_type, device='cuda:0', set=30, t_h=24, t_f=36, d_s=1 , enc_size = 64, grid_size = (13,3), upp_grid_size = (7,3)):\n        \n\n        self.dtype = dtype#{train, val, test}\n        self.data_dir = data_dir\n        self.dset = dsId#it means trajectory file\n        \n        print('load {} dataset'.format(self.dtype))\n        print(\"dtype is {} and dset(manual_seed) is {}\".format(self.dtype, self.dset))\n        if class_type == 'vehicle':\n            d= np.load(os.path.join(self.data_dir, self.dtype, \"{}Set{}-traj-v.npy\".format(self.dtype, self.dset)), allow_pickle=True)\n        elif class_type == 'bike/motor':\n            d= np.load(os.path.join(self.data_dir, self.dtype, \"{}Set{}-traj-b.npy\".format(self.dtype, self.dset)), allow_pickle=True)\n        elif class_type == 'human':\n            d= np.load(os.path.join(self.data_dir, self.dtype, \"{}Set{}-traj-h.npy\".format(self.dtype, self.dset)), allow_pickle=True)\n        else:\n            d= np.load(os.path.join(self.data_dir, self.dtype, \"{}Set{}-traj.npy\".format(self.dtype, self.dset)), allow_pickle=True)\n        self.D = d[0]\n        print(\"The size of TRAJ file: \", len(self.D))\n\n        t = np.load(os.path.join(self.data_dir, self.dtype, \"{}Set{}-track.npy\".format(self.dtype, self.dset)), allow_pickle=True)\n        self.T = t[0]\n        print(\"The size of TRACK file: \", len(self.T))\n\n        self.t_h = t_h  # length of track history#Ben: Input size (History)\n        self.t_f = t_f  # length of predicted trajectory#Ben: output size (Future)\n        self.d_s = d_s  # down sampling rate of all sequences# TODO#내가 만약 history를 6개를 보는데 d_s가 2라면 결국 띄엄띄엄해서 3개의 history를 보는 것.\n        self.enc_size = enc_size # size of encoder LSTM\n        self.grid_size = grid_size # size of social context grid\n        self.upp_grid_size = upp_grid_size #                                           #Behavioral Modification 2: Adding Kinetic Flow layer\n        self.inds = [14,15,16,17,18,19,20, 27,28,29,30,31,32,33, 40,41,42,43,44,45,46]# HORIZON; front Info.\n        #-->left top + center top + right top//BEN\n        # self.inds = [32,33,34,35]\n        self.dwn_inds = [8,9,10,11,12,13, 21,22,23,24,25,26, 34,35,36,37,38,39]# NEIGHBOR?; rear Info.\n        #-->left bottom + center bottom + right bottom//BEN\n        # self.dwn_inds = [35,36,37,38, 39]\n        self.device = device\n        self.ddd = [128, 128, 128, 129, 133, 133, 128]#dataset ids\n        self.vvv = [8, 11, 53, 21, 13, 22, 52]\n        self.fff = [2, 3, 2, 48, 2, 2, 16]\n        \n\n\n    def __len__(self):\n        return len(self.D)\n\n\n\n    def __getitem__(self, idx):\n\n        dsId = self.D[idx, 0].astype(int)# dsId.txt\n        vehId = self.D[idx, 1].astype(int)# unique Vehicle ID in dataset\n        t = self.D[idx, 2] # Frame\n        current = np.array([self.D[idx, 3:5]])# x, y\n        \n        grid = self.D[idx,8:47] # Ben: surrounding obstacles using distance# Neighbor! TODO\n        upp_grid = self.D[idx,self.inds]# Inner-distance of forward objects# Horizon! TODO\n        neighbors = []\n        upper_neighbors = []\n\n        hist = self.getHistory(vehId,t,vehId,dsId,current)#현재(t) 자신(vehId)의 x,y를 기준으로 과거(t부터t_h까지)의 상대적인 dx, dy\n        fut = self.getFuture(vehId,t,dsId)#현재(t) 자신(vehId)의 x,y를 기준으로 미래(t부터t_f까지)의 상대적인 dx, dy\n\n        # Get track histories of all neighbours 'neighbors' = [ndarray,[],ndarray,ndarray]\n        for i in grid:#NEIGHBOR's idx\n            #현재(t) 자신(vehId)의 x,y를 기준으로 Neighbor들의 과거(t부터t_h까지)의 상대적인 dx, dy\n            neighbors.append(self.getHistory(i.astype(int), t, vehId, dsId, current))            \n                                                                                        #Behavioral Modification 2: Adding Kinetic Flow layer\n            #현재(t) 자신(vehId)의 x,y를 기준으로 Horizon들의 과거(t부터t_h까지)의 상대적인 dx, dy\n        for i in upp_grid:#HORIZON's idx\n            upper_neighbors.append(self.getHistory(i.astype(int), t, vehId, dsId, current))\n\n        upp_count = np.count_nonzero(upp_grid)# front objects의 개수\n        dwn_count = np.count_nonzero(self.D[idx, self.dwn_inds])#rear objects의 개수\n        hist = np.concatenate((hist, np.array([[upp_count, dwn_count]])), axis=0)#len(hist) == t_h+3+1(?)\n        # Ben: hist는 결국 [자신의 t부터 t_h까지의 x,y ,\n        #                  t_h-t의 1/3 지점의 x,y   ,\n        #                  t_h-t의 2/3 지점의 x,y   ,\n        #                  t_h-t의 3/3 지점의 x,y   ,\n        #                  front, rear object의 개수]\n\n        # Maneuvers 'lon_enc' = one-hot vector, 'lat_enc = one-hot vector\n        lon_enc = np.zeros([2])\n        lon_enc[int(self.D[idx, 7] - 1)] = 1#lon_enc = [0, 1]\n        lat_enc = np.zeros([3])\n        lat_enc[int(self.D[idx, 6] - 1)] = 1#lat_enc = [0, 0, 1]\n\n        if dsId in self.ddd:# Don't know what it means...; maybe useless code?\n            idx = 0\n            while self.ddd[idx] != dsId:\n                idx += 1\n            if vehId == self.vvv[idx] and t == self.fff[idx]:\n                bb = True\n            else:\n                bb = False\n        else:\n            bb = False\n\n        return hist, fut, upper_neighbors, neighbors, lat_enc, lon_enc, bb, dsId, vehId, t\n        '''\n        hist = [자신의 t부터 t_h까지의 x,y , t_h-t의 1/3 지점의 x,y, t_h-t의 2/3 지점의 x,y ,\n                    t_h-t의 3/3 지점의 x,y, front, rear object의 개수]\n        fut = 현재(t) 자신(vehId)의 x,y를 기준으로 미래(t부터t_f까지)의 상대적인 dx, dy\n        upp_neighbors: 현재(t) 자신(vehId)의 x,y를 기준으로 Horizon들의 과거(t부터t_h까지)의 상대적인 dx, dy\n        neighbors: 현재(t) 자신(vehId)의 x,y를 기준으로 Neighbor들의 과거(t부터t_h까지)의 상대적인 dx, dy\n        lon_enc: [0, 1]\n        lat_enc: [0, 0, 1]\n        bb: False?\n        vehId: 현재 자신(vehId); object가 되겠죠.\n        t: 현재 frame\n        '''\n\n    ## Helper function to get track history\n    # refVeh: object's\n    # Veh: the master of the current row\n    def getHistory(self, vehId, t, refVehId, dsId, current):\n        # 결국, refVeh의 t에서의 x,y를 기준으로, veh의 t부터 t_h까지의 상대적인 x,y의 history\n        if vehId == 0:\n            return current\n        else:\n            if not vehId in self.T[dsId].keys():\n                out0 = np.full((self.t_h+3, 2), 0.0)#size==(9,2)\n                return out0\n\n            refTrack = (self.T[dsId][refVehId].transpose()).astype(float)\n            vehTrack = (self.T[dsId][vehId].transpose()).astype(float)\n            \n            # vehId의 refVehId가 같은 frame에 있었을 때의 x,y를 수집\n            refPos = refTrack[np.where(refTrack[:,0]==t)][0,1:3]#Ben: Other objects' pose at time t (at that frame)\n\n            if vehTrack.size==0 or np.argwhere(vehTrack[:, 0] == t).size==0:\n                out = np.full((self.t_h+3, 2), current+1e-3-refPos)#size==(9,2)\n                return out\n            else:\n                #현재t보다 t_h뒤의 index. 만약, 현재 t기준으로 t_h 뒤가 trajectory 초기의 t값 wmr, t-t_h <0이면, 그때는 0의 값을 갖는다.\n                stpt = np.maximum(0, np.argwhere(vehTrack[:, 0] == t).item(0)+1 - self.t_h)\n                #현재t보다 하나 더 앞의 index\n                enpt = np.argwhere(vehTrack[:, 0] == t).item(0) + 1\n                hist = vehTrack[stpt:enpt:self.d_s,1:3]-refPos#Get only relative positions [m]\n                #vehTrack에서 현재 stpt부터 enpt까지의 x,y\n            if len(hist) < self.t_h//self.d_s:\n                out2 = np.full((self.t_h, 2), 1e-3)\n                temp_vel = np.full((3,2), 1e-3)\n                out2[out2.shape[0]-hist.shape[0]:,:] = hist\n                out2 = np.concatenate((out2, temp_vel), axis=0)# velocity?\n                return out2\n                                                                                        # Behavioral Modification 3: Change inputs\n            m1 = int(self.t_h/3)#Ben: length of history / 3; 1/3지점\n            m2 = 2 * m1#2/3지점,,,,, t_h는 3/3지점.\n            vel0 = np.array([[hist[m1][0] - hist[0][0], hist[m1][1] -hist[0][1]]])#현재를 기준으로 우리가 보는 history길이의 1/3 전의 x,y\n            vel5 = np.array([[hist[m2][0] - hist[m1][0], hist[m2][1] -hist[m1][1]]])#현재를 기준으로 우리가 보는 history길이의 2/3 전의 x,y\n            vel10 = np.array([[hist[self.t_h-1][0] - hist[m2][0], hist[self.t_h-1][1] -hist[m2][1]]])#현재를 기준으로 우리가 보는 history길이의 끝에서의 x,y\n            hist = np.concatenate((hist, np.concatenate((vel0,vel5,vel10), axis=0)), axis=0)\n            return hist\n\n\n\n    ## Helper function to get track future\n    def getFuture(self, vehId, t,dsId):\n        # vehTrack = (self.T[dsId][vehId-1].transpose()).astype(float)\n        vehTrack = (self.T[dsId][vehId].transpose()).astype(float)\n        refPos = vehTrack[np.where(vehTrack[:, 0] == t)][0, 1:3]\n        stpt = np.argwhere(vehTrack[:, 0] == t).item(0) + self.d_s\n        enpt = np.minimum(len(vehTrack), np.argwhere(vehTrack[:, 0] == t).item(0) + self.t_f + 1)\n        fut = vehTrack[stpt:enpt:self.d_s,1:3]-refPos#Ben: Based on the current pose, get future gt trajectory\n        # print(dsId, vehId, vehTrack[stpt:enpt:self.d_s,1:3])\n        return fut#len(fut) is maybe different\n\n    ## Collate function for dataloader\n    def collate_fn(self, samples):\n        \n        # Initialize neighbors and neighbors length batches:\n        nbr_batch_size = 0\n\n        # upp_nbrs: horizon agent's relative poses\n        # nbrs: neighbor agent's relative poses\n        for _, _, upp_nbrs, nbrs, _, _, _, _, _, _ in samples:\n            nbr_batch_size += sum([len(nbrs[i])!=0 for i in range(len(nbrs))])\n        maxlen = self.t_h//self.d_s + 3 + 1\n        nbrs_batch = torch.zeros(maxlen,nbr_batch_size, 2)\n                                                                                                    # Behavioral Modification 2: Adding Kinetic Flow layer\n        upp_nbr_batch_size = 0\n        for _, _, upp_nbrs, nbrs,_ ,_ ,_ ,_ ,_ ,_ in samples:\n            upp_nbr_batch_size += sum([len(upp_nbrs[i])!=0 for i in range(len(upp_nbrs))])\n        upp_maxlen = self.t_h//self.d_s + 3 + 1                                                               # Behavioral Modification 3: Change inputs/ change max len to +3\n        upp_nbrs_batch = torch.zeros(upp_maxlen,upp_nbr_batch_size,2)\n\n        # Initialize social mask batch:#grid_size = (13,3), upp_grid_size = (7,3)\n        pos = [0, 0]\n        mask_batch = torch.zeros(len(samples), self.grid_size[1], self.grid_size[0], self.enc_size)\n        mask_batch = mask_batch.byte()\n\n        upp_pos = [0,0]                                                                                 # Behavioral Modification 2: Adding Kinetic Flow layer\n        upp_mask_batch = torch.zeros(len(samples), self.upp_grid_size[1], self.upp_grid_size[0], self.enc_size)\n        upp_mask_batch = upp_mask_batch.byte()\n\n\n        hist_batch = torch.zeros(maxlen,len(samples),2)\n        fut_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n        fut_mask_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n        lat_enc_batch = torch.zeros(len(samples),3)\n        lon_enc_batch = torch.zeros(len(samples), 2)\n        bb_batch = np.zeros(len(samples))\n        dd_batch = np.zeros(len(samples))\n        vv_batch = np.zeros(len(samples))\n        ff_batch = np.zeros(len(samples))\n\n        count = 0\n        upp_count = 0\n        # each sample: hist,fut,upper_neighbors, neighbors,lat_enc,lon_enc, bb, dsId, vehId, t\n        for sampleId,(hist, fut, upp_nbrs, nbrs, lat_enc, lon_enc, bb, dd, vv, ff) in enumerate(samples):\n            # Set up history, future, lateral maneuver and longitudinal maneuver batches:\n            hist_batch[0:len(hist),sampleId,0] = torch.from_numpy(hist[:, 0])   #x\n            hist_batch[0:len(hist), sampleId, 1] = torch.from_numpy(hist[:, 1]) #y\n            fut_batch[0:len(fut), sampleId, 0] = torch.from_numpy(fut[:, 0])\n            fut_batch[0:len(fut), sampleId, 1] = torch.from_numpy(fut[:, 1])\n            fut_mask_batch[0:len(fut),sampleId,:] = 1# if enough future doesn't exist --> zero\n            lat_enc_batch[sampleId,:] = torch.from_numpy(lat_enc)\n            lon_enc_batch[sampleId, :] = torch.from_numpy(lon_enc)\n            bb_batch[sampleId] = bb\n            dd_batch[sampleId] = dd\n            vv_batch[sampleId] = vv\n            ff_batch[sampleId] = ff\n\n            # Set up neighbor, neighbor sequence length, and mask batches:\n            for id,nbr in enumerate(nbrs):\n                if len(nbr)!=0:#if there is a history of nbrs\n                    nbrs_batch[0:len(nbr), count,0] = torch.from_numpy(nbr[:, 0])#x\n                    nbrs_batch[0:len(nbr), count, 1] = torch.from_numpy(nbr[:, 1])#y\n                    pos[0] = id % self.grid_size[0]#13\n                    pos[1] = id // self.grid_size[0]#13\n                    mask_batch[sampleId,pos[1],pos[0],:] = torch.ones(self.enc_size).byte()\n                    count+=1#each count, each neighbor\n\n                                                                                                   # Behavioral Modification 2: Adding Kinetic Flow layer\n            for id, upp_nbr in enumerate(upp_nbrs):\n                if len(upp_nbr) != 0:\n                    upp_nbrs_batch[0:len(upp_nbr), upp_count, 0] = torch.from_numpy(upp_nbr[:, 0])\n                    upp_nbrs_batch[0:len(upp_nbr), upp_count, 1] = torch.from_numpy(upp_nbr[:, 1])\n                    upp_pos[0] = id % self.upp_grid_size[0]#7\n                    upp_pos[1] = id // self.upp_grid_size[0]\n                    upp_mask_batch[sampleId, upp_pos[1], upp_pos[0], :] = torch.ones(self.enc_size).byte()#byte() just declares\n                    upp_count += 1\n\n        # print('it is from the collate_fn', hist_batch)\n        return hist_batch, upp_nbrs_batch, nbrs_batch, upp_mask_batch, mask_batch, lat_enc_batch, lon_enc_batch, fut_batch, fut_mask_batch, bb_batch, dd_batch, vv_batch, ff_batch\n\n#________________________________________________________________________________________________________________________________________\n\n\n\n\n\n## Custom activation for output layer (Graves, 2015)\ndef outputActivation(x):\n    muX = x[:,:,0:1]\n    muY = x[:,:,1:2]\n    sigX = x[:,:,2:3]\n    sigY = x[:,:,3:4]\n    rho = x[:,:,4:5]\n    sigX = torch.exp(sigX)\n    sigY = torch.exp(sigY)\n    rho = torch.tanh(rho)\n    out = torch.cat([muX, muY, sigX, sigY, rho],dim=2)\n    return out\n\n## Batchwise NLL loss, uses mask for variable output lengths\ndef maskedNLL(y_pred, y_gt, mask, device='cpu'):\n    acc = torch.zeros_like(mask, device=device)\n#     print(f\"y_pred value: {y_pred}\")\n    muX = y_pred[:,:,0]\n    muY = y_pred[:,:,1]\n    sigX = y_pred[:,:,2]\n    sigY = y_pred[:,:,3]\n    rho = y_pred[:,:,4]\n    ohr = torch.pow(1-torch.pow(rho,2),-0.5)\n    x = y_gt[:,:, 0]\n    y = y_gt[:,:, 1]\n    out = torch.pow(ohr, 2)*(torch.pow(sigX, 2)*torch.pow(x-muX, 2) + torch.pow(sigY, 2)*torch.pow(y-muY, 2) - 2*rho*torch.pow(sigX, 1)*torch.pow(sigY, 1)*(x-muX)*(y-muY)) - torch.log(sigX*sigY*ohr)\n    acc[:,:,0] = out\n    acc[:,:,1] = out\n    acc = acc*mask\n#    print(acc[0])\n    lossVal = torch.sum(acc)/torch.sum(mask)\n    return lossVal\n\n## NLL for sequence, outputs sequence of NLL values for each time-step, uses mask for variable output lengths, used for evaluation\ndef maskedNLLTest(fut_pred, lat_pred, lon_pred, fut, fut_mask, device='cpu',num_lat_classes=3, num_lon_classes = 2,use_maneuvers = True, avg_along_time = False, cuda=True):\n    if use_maneuvers:\n        if cuda:\n            acc = torch.zeros(fut_mask.shape[0],fut_mask.shape[1],num_lon_classes*num_lat_classes).cuda(device)\n        else:\n            acc = torch.zeros(fut_mask.shape[0],fut_mask.shape[1],num_lon_classes*num_lat_classes)\n        count = 0\n        for k in range(num_lon_classes):\n            for l in range(num_lat_classes):\n                wts = lat_pred[:,l]*lon_pred[:,k]\n                wts = wts.repeat(len(fut_pred[0]),1)\n                y_pred = fut_pred[k*num_lat_classes + l]\n                y_gt = fut\n                muX = y_pred[:, :, 0]\n                muY = y_pred[:, :, 1]\n                sigX = y_pred[:, :, 2]\n                sigY = y_pred[:, :, 3]\n                rho = y_pred[:, :, 4]\n                ohr = torch.pow(1 - torch.pow(rho, 2), -0.5)\n                x = y_gt[:, :, 0]\n                y = y_gt[:, :, 1]\n                out = -(torch.pow(ohr, 2) * (torch.pow(sigX, 2) * torch.pow(x - muX, 2) + torch.pow(sigY, 2) * torch.pow(y - muY,2) - 2 * rho * torch.pow(sigX, 1) * torch.pow(sigY, 1) * (x - muX) * (y - muY)) - torch.log(sigX * sigY * ohr))\n                acc[:, :, count] =  out + torch.log(wts)\n                count+=1\n        acc = -logsumexp(acc,dim = 2)\n        acc = acc * fut_mask[:,:,0]\n        if avg_along_time:\n            lossVal = torch.sum(acc) / torch.sum(fut_mask[:, :, 0])\n            return lossVal\n        else:\n            lossVal = torch.sum(acc,dim=1)\n            counts = torch.sum(fut_mask[:,:,0],dim=1)\n            return lossVal,counts\n    else:\n        if cuda:\n            acc = torch.zeros(fut_mask.shape[0], fut_mask.shape[1], 1).cuda(device)\n        else:\n            acc = torch.zeros(fut_mask.shape[0], fut_mask.shape[1], 1)\n        y_pred = fut_pred\n        y_gt = fut\n        muX = y_pred[:, :, 0]\n        muY = y_pred[:, :, 1]\n        sigX = y_pred[:, :, 2]\n        sigY = y_pred[:, :, 3]\n        rho = y_pred[:, :, 4]\n        ohr = torch.pow(1 - torch.pow(rho, 2), -0.5)\n        x = y_gt[:, :, 0]\n        y = y_gt[:, :, 1]\n        out = torch.pow(ohr, 2) * (\n        torch.pow(sigX, 2) * torch.pow(x - muX, 2) + torch.pow(sigY, 2) * torch.pow(y - muY, 2) - 2 * rho * torch.pow(\n            sigX, 1) * torch.pow(sigY, 1) * (x - muX) * (y - muY)) - torch.log(sigX * sigY * ohr)\n        acc[:, :, 0] = out\n        acc = acc * fut_mask[:, :, 0:1]\n        if avg_along_time:\n            lossVal = torch.sum(acc[:, :, 0]) / torch.sum(fut_mask[:, :, 0])\n            return lossVal\n        else:\n            lossVal = torch.sum(acc[:,:,0], dim=1)\n            counts = torch.sum(fut_mask[:, :, 0], dim=1)\n            return lossVal,counts\n\n## Batchwise MSE loss, uses mask for variable output lengths\ndef maskedMSE(y_pred, y_gt, mask, device='cpu'):\n    acc = torch.zeros_like(mask, device=device)\n#     print(f\"y_pred value: {y_pred}\")\n    muX = y_pred[:,:,0]\n    muY = y_pred[:,:,1]\n    x = y_gt[:,:, 0]\n    y = y_gt[:,:, 1]\n    out = torch.pow(x-muX, 2) + torch.pow(y-muY, 2)\n    acc[:,:,0] = out\n    acc[:,:,1] = out\n    acc = acc*mask\n#    print(acc)\n    lossVal = torch.sum(acc)/torch.sum(mask)\n    return lossVal\n\n## MSE loss for complete sequence, outputs a sequence of MSE values, uses mask for variable output lengths, used for evaluation\ndef maskedMSETest(y_pred, y_gt, mask, device='cpu'):\n    acc = torch.zeros_like(mask, device=device)\n    muX = y_pred[:, :, 0]\n    muY = y_pred[:, :, 1]\n    x = y_gt[:, :, 0]\n    y = y_gt[:, :, 1]\n    out = torch.pow(x - muX, 2) + torch.pow(y - muY, 2)\n    acc[:, :, 0] = out\n    acc[:, :, 1] = out\n    acc = acc * mask\n    lossVal = torch.sum(acc[:,:,0],dim=1)\n    counts = torch.sum(mask[:,:,0],dim=1)\n    return lossVal, counts\n\n## Helper function for log sum exp calculation:\ndef logsumexp(inputs, dim=None, keepdim=False):\n    if dim is None:\n        inputs = inputs.view(-1)\n        dim = 0\n    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n    if not keepdim:\n        outputs = outputs.squeeze(dim)\n    return outputs\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.474914Z","iopub.execute_input":"2024-04-22T05:36:08.475237Z","iopub.status.idle":"2024-04-22T05:36:08.575196Z","shell.execute_reply.started":"2024-04-22T05:36:08.475194Z","shell.execute_reply":"2024-04-22T05:36:08.574237Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction/social.py\nfrom __future__ import division\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\n# from model.Prediction.utils import outputActivation\n\nclass highwayNet(nn.Module):\n\n    ## Initialization\n    def __init__(self,args):\n        super(highwayNet, self).__init__()\n\n        ## Unpack arguments\n        self.args = args\n\n        ## Use gpu flag\n        self.use_cuda = args['cuda']\n\n        # Flag for maneuver based (True) vs uni-modal decoder (False)\n        self.use_maneuvers = args['use_maneuvers']\n\n        # Flag for train mode (True) vs test-mode (False)\n        self.train_flag = True\n\n        ## Sizes of network layers\n        self.encoder_size = args['encoder_size']\n        self.decoder_size = args['decoder_size']\n        self.in_length = args['in_length']\n        self.out_length = args['out_length']\n        self.grid_size = args['grid_size']\n        self.soc_conv_depth = args['soc_conv_depth']\n        self.conv_3x1_depth = args['conv_3x1_depth']\n        self.dyn_embedding_size = args['dyn_embedding_size']\n        self.input_embedding_size = args['input_embedding_size']\n        self.num_lat_classes = args['num_lat_classes']\n        self.num_lon_classes = args['num_lon_classes']\n        self.soc_embedding_size = (((args['grid_size'][0]-4)+1)//2)*self.conv_3x1_depth\n\n        ## Define network weights\n\n        # Input embedding layer\n        self.ip_emb = torch.nn.Linear(2,self.input_embedding_size)\n\n        # Encoder LSTM\n        self.enc_lstm = torch.nn.LSTM(self.input_embedding_size,self.encoder_size,1)\n#         self.enc_gru = torch.nn.GRU(self.input_embedding_size,self.encoder_size,1)\n        \n        # Vehicle dynamics embedding\n        self.dyn_emb = torch.nn.Linear(self.encoder_size,self.dyn_embedding_size)\n\n        # Convolutional social pooling layer and social embedding layer\n        self.soc_conv = torch.nn.Conv2d(self.encoder_size,self.soc_conv_depth,3)\n        self.conv_3x1 = torch.nn.Conv2d(self.soc_conv_depth, self.conv_3x1_depth, (3,1))\n        self.soc_maxpool = torch.nn.MaxPool2d((2,1),padding = (1,0))\n\n        # FC social pooling layer (for comparison):\n        # self.soc_fc = torch.nn.Linear(self.soc_conv_depth * self.grid_size[0] * self.grid_size[1], (((args['grid_size'][0]-4)+1)//2)*self.conv_3x1_depth)\n\n        # Decoder LSTM\n        if self.use_maneuvers:\n            self.dec_lstm = torch.nn.GRU(self.soc_embedding_size + self.dyn_embedding_size + self.num_lat_classes + self.num_lon_classes, self.decoder_size)\n        else:\n            self.dec_lstm = torch.nn.GRU(self.soc_embedding_size + self.dyn_embedding_size, self.decoder_size)\n\n        # Output layers:\n        self.op = torch.nn.Linear(self.decoder_size,5)\n        self.op_lat = torch.nn.Linear(self.soc_embedding_size + self.dyn_embedding_size, self.num_lat_classes)\n        self.op_lon = torch.nn.Linear(self.soc_embedding_size + self.dyn_embedding_size, self.num_lon_classes)\n\n        # Activations:\n        self.leaky_relu = torch.nn.LeakyReLU(0.1)\n        self.relu = torch.nn.ReLU()\n        self.softmax = torch.nn.Softmax(dim=1)\n\n#        self.bn_dec = torch.nn.BatchNorm1d(self.soc_embedding_size + self.dyn_embedding_size) \n\n\n    ## Forward Pass\n    def forward(self,hist,nbrs,masks,lat_enc,lon_enc):\n        \n        ## Forward pass hist:\n        _,(hist_enc,_) = self.enc_lstm(self.leaky_relu(self.ip_emb(hist)))\n        hist_enc = self.leaky_relu(self.dyn_emb(hist_enc.view(hist_enc.shape[1],hist_enc.shape[2])))\n        ## Forward pass nbrs\n        \n        _, (nbrs_enc,_) = self.enc_lstm(self.leaky_relu(self.ip_emb(nbrs)))\n        nbrs_enc = nbrs_enc.view(nbrs_enc.shape[1], nbrs_enc.shape[2])\n        ## Masked scatter\n        masks2 = masks.bool()\n        soc_enc = torch.zeros_like(masks).float()\n        soc_enc = soc_enc.masked_scatter_(masks2, nbrs_enc)\n        soc_enc = soc_enc.permute(0,3,2,1)\n\n        ## Apply convolutional social pooling:\n        soc_enc = self.soc_maxpool(self.leaky_relu(self.conv_3x1(self.leaky_relu(self.soc_conv(soc_enc)))))\n        soc_enc = soc_enc.view(-1,self.soc_embedding_size)\n\n        ## Apply fc soc pooling\n        # soc_enc = soc_enc.contiguous()\n        # soc_enc = soc_enc.view(-1, self.soc_conv_depth * self.grid_size[0] * self.grid_size[1])\n        # soc_enc = self.leaky_relu(self.soc_fc(soc_enc))\n        ## Concatenate encodings:\n        enc = torch.cat((soc_enc,hist_enc),1)\n\n\n        if self.use_maneuvers:\n            ## Maneuver recognition:\n            lat_pred = self.softmax(self.op_lat(enc))\n            lon_pred = self.softmax(self.op_lon(enc))\n\n            if self.train_flag:\n                ## Concatenate maneuver encoding of the true maneuver\n                enc = torch.cat((enc, lat_enc, lon_enc), 1)\n                fut_pred = self.decode(enc)\n                return fut_pred, lat_pred, lon_pred\n            else:\n                fut_pred = []\n                ## Predict trajectory distributions for each maneuver class\n                for k in range(self.num_lon_classes):\n                    for l in range(self.num_lat_classes):\n                        lat_enc_tmp = torch.zeros_like(lat_enc)\n                        lon_enc_tmp = torch.zeros_like(lon_enc)\n                        lat_enc_tmp[:, l] = 1\n                        lon_enc_tmp[:, k] = 1\n                        enc_tmp = torch.cat((enc, lat_enc_tmp, lon_enc_tmp), 1)\n                        fut_pred.append(self.decode(enc_tmp))\n                return fut_pred, lat_pred, lon_pred\n        else:\n#            enc = self.bn_dec(enc)\n            fut_pred = self.decode(enc)\n            return fut_pred\n\n\n    def decode(self,enc):\n        enc = enc.repeat(self.out_length, 1, 1)\n        h_dec, _ = self.dec_lstm(enc)\n        h_dec = h_dec.permute(1, 0, 2)\n        fut_pred = self.op(h_dec)\n        fut_pred = fut_pred.permute(1, 0, 2)\n        fut_pred = outputActivation(fut_pred)\n        return fut_pred\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.578052Z","iopub.execute_input":"2024-04-22T05:36:08.578685Z","iopub.status.idle":"2024-04-22T05:36:08.604815Z","shell.execute_reply.started":"2024-04-22T05:36:08.578653Z","shell.execute_reply":"2024-04-22T05:36:08.603886Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction/trajPredEngine\n# -*- coding: utf-8 -*-\nfrom ignite.engine import Engine, Events\n# from model.Prediction.utils import lstToCuda,maskedNLL,maskedMSE,maskedNLLTest, maskedMSETest\nimport math\nimport torch\nfrom ignite.contrib.handlers import ProgressBar\nimport os\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nimport matplotlib.pylab as plt\n\nclass TrajPredEngine:\n\n    def __init__(self, net, optim, train_loader, val_loader, args):\n        self.net = net\n        self.args = args\n        self.pretrainEpochs = args[\"pretrainEpochs\"]\n        self.trainEpochs = args[\"trainEpochs\"]\n        self.optim = optim\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.cuda = args['cuda']\n        self.device = args['device']\n        self.dsId = self.args['dsId']\n        self.n_iterations = max(len(train_loader), len(train_loader) / args[\"batch_size\"])\n\n        ## training metrics to keep track of, consider making a metrics class\n        # remember to 0 these out\n        self.avg_trn_loss = 0\n\n        self.metrics = {\"Avg train loss\": 0, \"Avg val loss\": 0 }\n        ## validation metrics\n        self.avg_val_loss = 0\n        self.val_batch_count = 1\n\n        # only if using maneuvers\n        self.avg_lat_acc = 0\n        self.avg_lon_acc = 0\n\n        self.trainer = None\n        self.evaluator = None\n\n        self.makeTrainer()\n\n        self.save_name = args['name']\n\n        # testing stuff wow need 2 clean this so bad\n\n        self.lossVals = torch.zeros(self.args['out_length']).cuda(self.device) if self.cuda else torch.zeros(self.args['out_length'])\n        self.counts = torch.zeros(self.args['out_length']).cuda(self.device) if self.cuda else torch.zeros(self.args['out_length'])\n        self.lastTestLoss = 0\n        \n        self.writer = None\n        self.log_dir = args['log_dir']\n        self.tensorboard = args['tensorboard']\n\n        # Ben\n        self.current_best = 1000\n        self.best_epoch = 0\n\n    def netPred(self, batch):\n        raise NotImplementedError\n\n    def saveModel(self, engine):\n\n        os.makedirs(self.args['modelLoc'], exist_ok=True)\n        name = os.path.join(self.args['modelLoc'], \"epochs.{}.\".format(engine.state.epoch)+self.args['name'])\n        torch.save(self.net.state_dict(), name)\n        print(\"Model saved {}.\".format(name))\n\n    def train_a_batch(self, engine, batch):\n        # each sample: hist,fut,upper_neighbors, neighbors,lat_enc,lon_enc, bb, dsId, vehId, t\n        self.net.train_flag = True\n        epoch = engine.state.epoch\n\n        _, _, _, _, _, _, _, fut, op_mask, _, _, _, _ = batch\n\n        fut_pred = self.netPred(batch)\n        \n        if self.cuda:\n            fut = fut.cuda(self.device)\n            op_mask = op_mask.cuda(self.device)\n\n\n        if self.args['nll_only']:\n            l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n        elif epoch < self.pretrainEpochs:\n            if self.args[\"pretrain_loss\"] == 'MSE':\n                l = maskedMSE(fut_pred, fut, op_mask, device=self.device)\n            elif self.args['pretrain_loss'] == 'NLL':\n                l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n            else:\n                l = maskedMSE(fut_pred, fut, op_mask, device=self.device)\n        else:\n            if self.args[\"train_loss\"] == 'MSE':\n                l = maskedMSE(fut_pred, fut, op_mask, device=self.device)\n            elif self.args['train_loss'] == 'NLL':\n                l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n            else:\n                l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n\n        # if self.args['nll_only']:\n        #     l = maskedNLL(fut_pred, fut, op_mask)\n        # else:\n        #     if epoch < self.pretrainEpochs:\n        #         l = maskedMSE(fut_pred, fut, op_mask)\n        #     else:\n        #         l = maskedNLL(fut_pred, fut, op_mask)\n\n        # Backprop and update weights\n#        if l.item() != l.item():\n#            print(l.item())\n#            exit(1)\n#            return 1\n        self.optim.zero_grad()\n        l.backward()\n        self.optim.step()\n\n        # Track average train loss:\n        self.avg_trn_loss += l.item()\n        self.metrics[\"Avg train loss\"] += l.item() / 100.0\n           \n        # if self.writer:#Ben: if you want to write down the loss, every epoch\n            # print(\"writing...\")\n            # self.writer.add_scalar(\"{}epoch/trainingloss\".format(engine.state.epoch), l.item() , engine.state.iteration)\n            # def saveModel(self, engine):\n            #     os.makedirs(self.args['modelLoc'], exist_ok=True)\n            #     name = os.path.join(self.args['modelLoc'], self.args['name'])\n            #     torch.save(self.net.state_dict(), name)\n            #     print(\"Model saved {}.\".format(name))\n\n\n        return l.item()\n\n    def eval_a_batch(self, engine, batch):\n        self.net.train_flag = False\n\n        epoch = engine.state.epoch\n\n        _, _, _, _, _, _, _, fut, op_mask, _, _, _, _ = batch\n        fut_pred = self.netPred(batch)\n        if self.cuda:\n            fut = fut.cuda(self.device)\n            op_mask = op_mask.cuda(self.device)\n\n        # Forward pass\n        if self.args['nll_only']:\n            l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n        elif epoch < self.pretrainEpochs:\n            if self.args[\"pretrain_loss\"] == 'MSE':\n                l = maskedMSE(fut_pred, fut, op_mask, device=self.device)\n            elif self.args['pretrain_loss'] == 'NLL':\n                l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n            else:\n                l = maskedMSE(fut_pred, fut, op_mask, device=self.device)\n        else:\n            if self.args[\"train_loss\"] == 'MSE':\n                l = maskedMSE(fut_pred, fut, op_mask, device=self.device)\n            elif self.args['train_loss'] == 'NLL':\n                l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n            else:\n                l = maskedNLL(fut_pred, fut, op_mask, device=self.device)\n\n\n        # if self.args['nll_only']:\n        #     l = maskedNLL(fut_pred, fut, op_mask)\n        # else:\n        #     if epoch_num < pretrainEpochs:\n        #         l = maskedMSE(fut_pred, fut, op_mask)\n        #     else:\n        #         l = maskedNLL(fut_pred, fut, op_mask)\n\n        self.avg_val_loss += l.item()\n        self.metrics[\"Avg val loss\"] += l.item()/ (self.val_batch_count * 100.0)\n        self.val_batch_count += 1\n\n        return fut_pred, fut\n\n    def validate(self, engine):\n        self.evaluator.run(self.val_loader)\n        max_epochs =self.args[\"pretrainEpochs\"] + self.args[\"trainEpochs\"]\n\n        # if not self.eval_only:\n        print(\"{}/{} Epochs in dataset{}\".format(engine.state.epoch, max_epochs, self.dsId))\n        # print(max((engine.state.epoch / max_epochs) * 100,1))\n        print(\"EPOCH {}: Train loss: {}  Val loss: {}\\n\".format(engine.state.epoch, self.metrics[\"Avg train loss\"], self.metrics[\"Avg val loss\"]))\n        # else:\n        #     print(\"EPOCH {}: Test loss: {}\\n\".format(engine.state.epoch, self.metrics[\"Avg val loss\"]))\n        if self.metrics['Avg val loss'] == min(self.metrics['Avg val loss'], self.current_best):\n            self.best_epoch = engine.state.epoch\n            self.current_best = self.metrics['Avg val loss']\n        print(\"CURRENT BEST: \", self.best_epoch)\n        if self.writer:\n            self.writer.add_scalar(\"training_avg_loss\", self.metrics['Avg train loss'], engine.state.epoch)\n            self.writer.add_scalar(\"validating_avg_loss\", self.metrics['Avg val loss'], engine.state.epoch)\n\n        self.metrics[\"Avg train loss\"] = 0\n        self.metrics[\"Avg val loss\"] = 0\n\n    def zeroMetrics(self, engine):\n        self.val_batch_count = 1\n        self.metrics[\"Avg val loss\"] = 0 \n\n    def zeroTrainLoss(self, engine):\n        self.metrics[\"Avg train loss\"] = 0\n\n    def zeroValLoss(self, engine):\n        self.metrics[\"Avg val loss\"] = 0\n\n    def makeTrainer(self):\n        self.trainer = Engine(self.train_a_batch)\n        self.evaluator = Engine(self.eval_a_batch)\n\n        pbar = ProgressBar(persist=True, postfix=self.metrics)\n        pbar.attach(self.trainer)\n        pbar.attach(self.evaluator)\n\n        ## attach hooks \n        self.trainer.add_event_handler(Events.EPOCH_COMPLETED, self.validate)\n        self.trainer.add_event_handler(Events.EPOCH_COMPLETED, self.saveModel)\n        self.trainer.add_event_handler(Events.ITERATION_COMPLETED, self.zeroMetrics)\n        self.trainer.add_event_handler(Events.COMPLETED, self.saveModel)\n        # zero out metrics for next epoch\n\n\n    def create_summary_writer(self, model, data_loader, log_dir):\n        writer = SummaryWriter(log_dir=log_dir)\n        data_loader_iter = iter(data_loader)\n        b = next(data_loader_iter)\n        b = tuple(x for x in b)\n#         b = tuple(x.cuda(self.device) for x in b)\n        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        b_gpu = tuple(x.to(device) for x in b[:7])\n        try:\n            writer.add_graph(model, b_gpu[:7])\n        except Exception as e:\n            print(\"Failed to save model graph: {}\".format(e))\n        return writer\n\n    def start(self):\n        max_epochs =self.args[\"pretrainEpochs\"] + self.args[\"trainEpochs\"]\n\n        if self.tensorboard:\n            self.writer = self.create_summary_writer(self.net, self.train_loader, self.log_dir)\n\n        @self.trainer.on(Events.ITERATION_COMPLETED)\n        def log_training_loss(engine):\n            iter = (engine.state.iteration - 1) % len(self.train_loader) + 1\n            self.writer.add_scalar(\"training/loss\", engine.state.output, engine.state.iteration)\n        #    if iter % 10 == 0:\n#         print(\"============Running============\")\n        # if not self.eval_only:\n        self.trainer.run(self.train_loader, max_epochs=max_epochs)\n        # else:\n            # self.trainer.run(self.train_loader, max_epochs=1)\n\n        if self.tensorboard:\n            self.writer.close()\n\n\n    def test_a_batch(self, engine, batch):\n        # print(\"test a batch------------==================================\")\n        # _, _, _, _, _, _, _, fut, op_mask, _, _, _, _ = batch\n        hist_trj, _, _, _, _, _, _, fut, op_mask, _, _, vehId, _ = batch\n\n\n        # Initialize Variables\n        if self.cuda:\n            fut = fut.cuda(self.device)\n            op_mask = op_mask.cuda(self.device)\n\n        if self.args[\"train_loss\"] == 'NLL':\n            # Forward pass\n            if self.args['use_maneuvers']:\n                fut_pred, lat_pred, lon_pred = self.netPred(batch)\n                l,c = maskedNLLTest(fut_pred, lat_pred, lon_pred, fut, op_mask, device=self.device, cuda=self.args.cuda)\n            else:\n                fut_pred = self.netPred(batch)\n                l, c = maskedNLLTest(fut_pred, 0, 0, fut, op_mask, device=self.device, use_maneuvers=False, cuda=self.cuda)\n        else:\n            # Forward pass\n            if self.args['use_maneuvers']:\n                fut_pred, lat_pred, lon_pred = self.netPred(batch)\n                fut_pred_max = torch.zeros_like(fut_pred[0])\n                for k in range(lat_pred.shape[0]):\n                    lat_man = torch.argmax(lat_pred[k, :]).detach()\n                    lon_man = torch.argmax(lon_pred[k, :]).detach()\n                    indx = lon_man*3 + lat_man\n                    fut_pred_max[:,k,:] = fut_pred[indx][:,k,:]\n                l, c = maskedMSETest(fut_pred_max, fut, op_mask, device=self.device)\n            else:\n                fut_pred = self.netPred(batch)            \n                l, c = maskedMSETest(fut_pred, fut, op_mask, device=self.device)\n        fut_pred_info = fut_pred.cpu().detach().numpy()##BEN\n        \n        \n        # print(\"\\n vehicle Id from the net: \", vehId)\n        # print(\"hist_traj: \", hist_trj)\n        # print(\"GT_trj: \", fut)\n        # print(\"Net_trj: \", fut_pred_info[:,:,:2])\n\n        # # print(\"future_prediction: \", fut_pred_info.shape)\n        # quit()\n        self.lossVals +=l.detach()\n        self.lastTestLoss = l.detach()\n        self.counts += c.detach()\n\n\n\n    def eval(self, test_loader):\n\n\n        self.test_batch_size = len(test_loader)\n        tester = Engine(self.test_a_batch)\n\n        pbar = ProgressBar(persist=True, postfix=self.metrics)\n        pbar.attach(tester)\n        print('evaluating on dataset{}...'.format(self.dsId))\n        tester.run(test_loader)\n        \n        if(self.args[\"train_loss\"]) == \"NLL\" :\n            nll_loss = self.lossVals / self.counts\n            nll_loss[nll_loss != nll_loss] = 0\n            print(\"Last Test loss: \" + str(self.lastTestLoss.mean().item()))\n            print(\"Avg Test loss: \" + str(nll_loss.mean().item()))\n        else:\n            rmse = torch.pow(self.lossVals / self.counts, 0.5) * .3048 # converting from feet to meters\n            rmse[torch.isnan(rmse)] = 0\n            # self.lastTestLoss = torch.pow(self.lastTestLoss, 0.5) * .3048\n            # print(self.lastTestLoss)\n            seq_loss = rmse.tolist()\n            seq_loss = [x for x in seq_loss if x != 0]\n            print(rmse)\n            print(\"Last Test loss: \" + str(seq_loss[-1]))\n            print(\"Avg Test loss: \" + str(rmse.mean().item()))\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.606349Z","iopub.execute_input":"2024-04-22T05:36:08.606663Z","iopub.status.idle":"2024-04-22T05:36:08.663101Z","shell.execute_reply.started":"2024-04-22T05:36:08.606619Z","shell.execute_reply":"2024-04-22T05:36:08.662162Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction/traphicEngine\n# from model.Prediction.trajPredEngine import TrajPredEngine\nimport torch\nimport datetime\nimport numpy as np\nclass TraphicEngine(TrajPredEngine):\n    \"\"\"\n    Implementation of abstractEngine for traphic\n    TODO:maneuver metrics, too much duplicate code with socialEngine\n    \"\"\"\n\n    def __init__(self, net, optim, train_loader, val_loader, args):\n        super().__init__(net, optim, train_loader, val_loader, args)\n        self.save_name = \"traphic\"\n\n    def netPred(self, batch):\n        hist, upp_nbrs, nbrs, upp_mask, mask, lat_enc, lon_enc, fut, fut_mask, b, d, v, f = batch\n\n        if self.args['cuda']:\n            hist = hist.cuda(self.device)\n            nbrs = nbrs.cuda(self.device)\n            upp_nbrs = upp_nbrs.cuda(self.device)\n            mask = mask.cuda(self.device)\n            upp_mask = upp_mask.cuda(self.device)\n            lat_enc = lat_enc.cuda(self.device)\n            lon_enc = lon_enc.cuda(self.device)\n            fut = fut.cuda(self.device)\n            fut_mask = fut_mask.cuda(self.device)\n        \n        fut_pred  = self.net(hist, upp_nbrs, nbrs, upp_mask, mask, lat_enc, lon_enc)\n\n        return fut_pred\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.664399Z","iopub.execute_input":"2024-04-22T05:36:08.664681Z","iopub.status.idle":"2024-04-22T05:36:08.677067Z","shell.execute_reply.started":"2024-04-22T05:36:08.664657Z","shell.execute_reply":"2024-04-22T05:36:08.676191Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction/socialEngine.py\n# from model.Prediction.trajPredEngine import TrajPredEngine\nimport torch\n\nclass SocialEngine(TrajPredEngine):\n    \"\"\"\n    Implementation of abstractEngine for traphic\n    TODO:maneuver metrics, too much duplicate code with socialEngine\n    \"\"\"\n\n    def __init__(self, net, optim, train_loader, val_loader, args):\n        super().__init__(net, optim, train_loader, val_loader, args)\n        self.save_name = \"social\"\n\n    def netPred(self, batch):\n        hist, _, nbrs, _, mask, lat_enc, lon_enc, _, _, b, d, v, f = batch\n        if self.args['cuda']:\n            hist = hist.cuda(self.device)\n            nbrs = nbrs.cuda(self.device)\n            mask = mask.cuda(self.device)\n            lat_enc = lat_enc.cuda(self.device)\n            lon_enc = lon_enc.cuda(self.device)\n        fut_pred  = self.net(hist, nbrs, mask, lat_enc, lon_enc)\n        return fut_pred\n\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.678061Z","iopub.execute_input":"2024-04-22T05:36:08.679159Z","iopub.status.idle":"2024-04-22T05:36:08.691208Z","shell.execute_reply.started":"2024-04-22T05:36:08.679127Z","shell.execute_reply":"2024-04-22T05:36:08.690368Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction/traphic.py\n\n# -*- coding: utf-8 -*-\nfrom __future__ import division\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nfrom tensorboardX import SummaryWriter\n\n\nclass traphicNet(nn.Module):\n    def __init__(self, args):\n        print(\"===================Execute Model Iitialization===========\")\n        super(traphicNet, self).__init__()\n        self.args = args\n        self.use_cuda = args['cuda']\n        self.use_maneuvers = args['use_maneuvers']\n        self.train_flag = True\n\n        self.dropout_prob = args['dropout_prob']\n        self.encoder_size = args['encoder_size']\n        self.decoder_size = args['decoder_size']\n        self.in_length = args['in_length']\n        self.out_length = args['out_length']\n        self.grid_size = args['grid_size']\n        self.upp_grid_size = args['upp_grid_size']\n        self.soc_conv_depth = args['soc_conv_depth']\n        self.conv_3x1_depth = args['conv_3x1_depth']\n        self.dyn_embedding_size = args['dyn_embedding_size']\n        self.input_embedding_size = args['input_embedding_size']\n        self.num_lat_classes = args['num_lat_classes']\n        self.num_lon_classes = args['num_lon_classes']\n        self.soc_embedding_size = (((args['grid_size'][0]-4)+1)//2)*self.conv_3x1_depth\n        self.upp_soc_embedding_size = (((args['upp_grid_size'][0]-4)+1)//2)*self.conv_3x1_depth\n        self.ours = args['ours']\n\n        self.ip_emb = torch.nn.Linear(2, self.input_embedding_size)\n\n        if self.ours:\n            self.ip_emb_vel = torch.nn.Linear(2, self.input_embedding_size)\n            self.ip_emb_nc = torch.nn.Linear(2, self.input_embedding_size)\n\n        self.enc_gru = torch.nn.GRU(self.input_embedding_size, self.encoder_size, 1)\n\n        self.dyn_emb = torch.nn.Linear(self.encoder_size, self.dyn_embedding_size)\n        self.bn_conv = torch.nn.BatchNorm2d(self.encoder_size)\n\n        if self.ours:\n            self.beh_1 = torch.nn.Linear(self.encoder_size, self.encoder_size)\n\n        self.soc_conv = torch.nn.Conv2d(self.encoder_size, self.soc_conv_depth, 3)\n        self.conv_3x1 = torch.nn.Conv2d(self.soc_conv_depth, self.conv_3x1_depth, (3,1))\n        self.soc_maxpool = torch.nn.MaxPool2d((2,1), padding=(1,0))\n\n        if self.use_maneuvers:\n            self.dec_gru = torch.nn.GRU(self.upp_soc_embedding_size + self.soc_embedding_size + self.dyn_embedding_size + self.num_lat_classes + self.num_lon_classes, self.decoder_size)\n        else:\n            self.dec_gru = torch.nn.GRU(self.soc_embedding_size + self.dyn_embedding_size, self.decoder_size, dropout=self.dropout_prob)\n\n        self.bnupp_soc_enc = torch.nn.BatchNorm1d(self.input_embedding_size)\n        self.bn_soc_enc = torch.nn.BatchNorm1d(self.soc_embedding_size)\n        self.bn_hist_enc = torch.nn.BatchNorm1d(self.upp_soc_embedding_size)\n\n        self.op = torch.nn.Linear(self.decoder_size, 5)\n        self.bn_lin = torch.nn.BatchNorm1d(self.out_length)\n\n        self.dropout = nn.Dropout(self.dropout_prob)\n\n        if self.ours:\n            self.op_lat = torch.nn.Linear(self.upp_soc_embedding_size + self.soc_embedding_size + self.dyn_embedding_size, self.num_lat_classes)\n            self.op_lon = torch.nn.Linear(self.upp_soc_embedding_size + self.soc_embedding_size + self.dyn_embedding_size, self.num_lon_classes)\n        else:\n            self.op_lat = torch.nn.Linear(self.soc_embedding_size + self.dyn_embedding_size, self.num_lat_classes)\n            self.op_lon = torch.nn.Linear(self.soc_embedding_size + self.dyn_embedding_size, self.num_lon_classes)\n\n        self.leaky_relu = torch.nn.ELU()\n        self.softmax = torch.nn.Softmax(dim=1)\n\n        self.summary = None\n        if self.args['tensorboard']:\n            self.summary = SummaryWriter()\n\n\n    def forward(self, hist, upp_nbrs, nbrs, upp_masks, masks, lat_enc, lon_enc):\n#         print(\"===============Execute Forward Pass =============\")\n        # Forward pass hist\n        if self.ours:\n            temp = self.leaky_relu(torch.cat((self.ip_emb(hist[0:self.in_length,:,:]), self.ip_emb_vel(hist[self.in_length:,:,:])), 0))\n            _, hist_enc = self.enc_gru(temp)  # Add unsqueeze to make the input 3-D\n            hist_enc = hist_enc.squeeze(0)  # Remove extra dimension added by unsqueeze\n        else:\n            _, hist_enc = self.enc_gru(self.leaky_relu(self.ip_emb(hist)))\n        \n#         print(\"===============Execute Forward Pass Debug point 1 =============\")\n        hist_enc = self.leaky_relu(self.dyn_emb(hist_enc.view(hist_enc.shape[0], hist_enc.shape[1])))\n#         print(\"===============Execute Forward Pass Debug point 2 =============\")\n        # Forward pass nbrs\n        if self.ours:\n#             print(\"===============Execute Forward Pass Debug point 1 =============\")\n            _, nbrs_enc = self.enc_gru(self.leaky_relu(torch.cat((self.ip_emb(nbrs[0:self.in_length,:,:]), self.ip_emb_vel(nbrs[self.in_length:,:,:])), 0)))  # Add unsqueeze to make the input 3-D\n#             print(\"===============Execute Forward Pass Debug point 2 =============\")\n            nbrs_enc = nbrs_enc.squeeze(0)  # Remove extra dimension added by unsqueeze\n        else:\n            _, (nbrs_enc, _) = self.enc_gru(self.leaky_relu(self.ip_emb(nbrs)))\n\n        nbrs_enc = nbrs_enc.view(nbrs_enc.shape[0], nbrs_enc.shape[1])\n        \n        if self.ours:\n            a = self.ip_emb(upp_nbrs[0:self.in_length,:,:])\n            b = self.ip_emb_vel(upp_nbrs[self.in_length:,:,:])\n            c = self.leaky_relu(torch.cat((a,b)))\n            _, upp_nbrs_enc = self.enc_gru(c)  # Add unsqueeze to make the input 3-D\n            upp_nbrs_enc = upp_nbrs_enc.squeeze(0)  # Remove extra dimension added by unsqueeze\n            upp_nbrs_enc = upp_nbrs_enc.view(upp_nbrs_enc.shape[0], upp_nbrs_enc.shape[1])\n\n            nbrs_enc = self.leaky_relu(self.beh_1(nbrs_enc))\n            upp_nbrs_enc = self.leaky_relu(self.beh_1(upp_nbrs_enc))\n#         print(\"===============Execute Forward Pass Debug point 20 =============\")\n        # Masked scatter\n        masks2 = masks.bool()\n        soc_enc = torch.zeros_like(masks).float()\n        soc_enc = soc_enc.masked_scatter_(masks2, nbrs_enc)\n        soc_enc = soc_enc.permute(0,3,2,1)\n\n        if self.ours:\n            upp_masks2 = upp_masks.bool()\n            upp_soc_enc = torch.zeros_like(upp_masks).float()\n            upp_soc_enc = upp_soc_enc.masked_scatter_(upp_masks2, upp_nbrs_enc)\n            upp_soc_enc = upp_soc_enc.permute(0,3,2,1)\n\n        # Apply convolutional social pooling:maxpool\n        soc_enc = self.soc_maxpool(self.leaky_relu(self.dropout(self.conv_3x1(self.bn_conv(self.leaky_relu(self.soc_conv(soc_enc)))))))\n        soc_enc = soc_enc.view(-1, self.soc_embedding_size)\n#         print(\"===============Execute Forward Pass Debug point 3 =============\")\n        if self.ours:\n            upp_soc_enc = self.soc_maxpool(self.leaky_relu(self.dropout(self.conv_3x1(self.bn_conv(self.leaky_relu(self.soc_conv(upp_soc_enc)))))))\n            upp_soc_enc = upp_soc_enc.view(-1, self.upp_soc_embedding_size)\n#         print(\"===============Execute Forward Pass Debug point 30 =============\")/\n        # Apply fc soc pooling\n        if self.ours:\n#             print(\"===============Execute Forward Pass Debug point 31 =============\")\n#             print(upp_soc_enc.shape)\n#             print(soc_enc.shape)\n#             print(hist_enc.shape)\n            enc = torch.cat((self.bnupp_soc_enc(upp_soc_enc), self.bn_soc_enc(soc_enc)), 1)\n        else:\n            enc = torch.cat((soc_enc, hist_enc), 1)\n\n        if self.use_maneuvers:\n#             print(\"===============Execute Forward Pass Debug point 32 =============\")\n            # Maneuver recognition\n            lat_pred = self.softmax(self.op_lat(enc))\n            lon_pred = self.softmax(self.op_lon(enc))\n\n#             print(\"===============Execute Forward Pass Debug point 30 =============\")\n            if self.train_flag:\n                # Concatenate maneuver encoding of the true maneuver\n                enc = torch.cat((enc, lat_enc, lon_enc), 1)\n                fut_pred = self.decode(enc)\n#                 print(\"Debug fut_pred_print pos-1\")\n#                 print(f\"fut_pred value: {fut_pred}\")\n                return fut_pred, lat_pred, lon_pred\n            else:\n                fut_pred = []\n                # Predict trajectory distributions for each maneuver class\n                for k in range(self.num_lon_classes):\n                    for l in range(self.num_lat_classes):\n                        lat_enc_tmp = torch.zeros_like(lat_enc)\n                        lon_enc_tmp = torch.zeros_like(lon_enc)\n                        lat_enc_tmp[:, l] = 1\n                        lon_enc_tmp[:, k] = 1\n                        enc_tmp = torch.cat((enc, lat_enc_tmp, lon_enc_tmp), 1)\n                        fut_pred.append(self.decode(enc_tmp))\n#                 print(\"Debug fut_pred_print pos-2\")\n#                 print(f\"fut_pred value: {fut_pred}\")\n                return fut_pred, lat_pred, lon_pred\n        else:\n#             print(f\"enc value: {enc}\")\n            fut_pred = self.decode(enc)\n#             print(\"Debug fut_pred_print pos-3\")\n#             print(f\"fut_pred value: {fut_pred}\")\n            return fut_pred\n\n\n    def decode(self, enc):\n        enc = enc.repeat(self.out_length, 1, 1)\n        h_dec, _ = self.dec_gru(enc)\n        h_dec = h_dec.permute(1, 0, 2)\n        fut_pred = self.op(h_dec)\n        fut_pred = self.bn_lin(fut_pred)\n        fut_pred = fut_pred.permute(1, 0, 2)\n        fut_pred = self.dropout(fut_pred)\n        fut_pred = outputActivation(fut_pred)\n        return fut_pred\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.692480Z","iopub.execute_input":"2024-04-22T05:36:08.692747Z","iopub.status.idle":"2024-04-22T05:36:08.733118Z","shell.execute_reply.started":"2024-04-22T05:36:08.692724Z","shell.execute_reply":"2024-04-22T05:36:08.732260Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#model/import_data.py\n# -*- coding: utf-8 -*-\nimport re\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport os\nimport sys\n# np.set_printoptions(threshold=sys.maxsize)\n\n\ndef import_data(file_dir, homography_dir, out_dir, class_type):\n    transform(file_dir, homography_dir, out_dir, class_type)\n\ndef merge(file_names, output_dir, dtype, threadid, class_type):\n    '''\n    file_names: .npy file's lists\n    output_dir: txt set list, without .txt\n    결국, merge가 하는 일은 dsId.txt들을 하나의 .npy로 정리한 것.\n    \n    raw dataset:\n    dsId1.txt, dsId2.txt, dsId3.txt, ..., dsIdN.txt\n\n    final dataset for NN:\n    Set#-traj.npy: \n    [ [ [dsId1, vehId(1), frame1, x, y, ----- i's features -----],\n        [dsId1, vehId(2), frame1, x, y, ----- i's features -----],\n        [dsId1, vehId(3), frame1, x, y, ----- i's features -----],\n                                ... ,\n        [dsId1, vehId(f1), frame1, x, y, ----- i's features -----],\n        [dsId1, vehId(1), frame2, x, y, ----- i's features -----],\n        [dsId1, vehId(2), frame2, x, y, ----- i's features -----],\n                                ... ,\n        [dsId1, vehId(fM_1), frameM_1, x, y, ----- i's features -----],\n        \n\n        [dsId2, vehId(1), frame1, x, y, ----- i's features -----],\n                                ... ,\n        [dsId2, vehId(fM_2), frameM_2, x, y, ----- i's features -----],\n\n\n                                ... ,\n        [dsIdN, vehId(i), frame, x, y, ----- i's features -----] ] ]\n\n    Set#-track.npy:\n      [ {\n            dsId1: {\n                    vehId(1): [frame, x, y]'s history,\n                    vehId(2): [frame, x, y]'s history,\n                                    ... ,\n                    vehId(p1): [frame, x, y]'s history\n                    }\n\n            dsId2:  {\n                    vehId(1): [frame, x, y]'s history,\n                    vehId(2): [frame, x, y]'s history,\n                                    ... ,\n                    vehId(p2): [frame, x, y]'s history\n                    }\n                ...\n            \n            dsIdN:  {\n                    vehId(1): [frame, x, y]'s history,\n                    vehId(2): [frame, x, y]'s history,\n                                    ... ,\n                    vehId(pN): [frame, x, y]'s history\n                    }\n        } ]\n    '''\n    output_dir = output_dir + '/{}'\n    traj = np.array([])\n\n    track = defaultdict(dict)\n\n    i = 0\n    sz = len(file_names)\n    for f in file_names:#get .npy file\n        print(\"Start merging {}/{} in {} in thread {}...\".format(i, sz, dtype, threadid))\n        i += 1\n        # print(\"Reading dataset {}...\".format(d))\n        npy_path = f\n        print('reading... ', npy_path)\n        data = np.load(npy_path, allow_pickle=True)# get formated .npy file\n\n        # print('data', data.shape)\n        # constructing train, val and testset for trajectory\n        data0 = data[0]#traj data for a specific class\n        data2 = data[2]#traj data for all\n        \n        traj_id = np.unique(data2[:,1])# get all object_id from dset 'd' if you make dataset for specific agent type\n        \n        if len(data0)==0:\n            continue\n        d = int(data0[0, 0])#dataset id\n        \n\n        if traj.size == 0:\n            traj = data0\n        else:\n            '''# traj는 모든 #.npy의 traj를 합친 파일.'''\n            traj = np.concatenate((traj, data0), axis=0)\n\n        # constructing train, val and testset for tracks\n        data1 = data[1]#track dataset from 'transform' function\n        for ids in traj_id:#(t, x, y)\n            '''# track은 모든 .npy의 track을 저장한 파일.'''\n            track[d][ids] = data1[ids]#literally, each object's trajectory\n\n        # print(\"Dataset {} finsihed.\".format(d))\n    \n    if not os.path.exists(output_dir.format(dtype)):\n        os.makedirs(output_dir.format(dtype))\n\n    # data for sgan\n    # sgan_name = \"{}/{}Set{}.txt\".format(dtype, dtype, str(threadid))\n    # f = open(output_dir.format(sgan_name), 'w')\n    # for line in traj:\n    #     # f.write(\"{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4]))\n    #     f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4], int(line[0])))\n    # f.close()\n\n    if class_type == 'vehicle':\n        npy_name = \"{}/{}Set{}-traj-v.npy\".format(dtype, dtype, str(threadid))\n    elif class_type == 'bike/motor':\n        npy_name = \"{}/{}Set{}-traj-b.npy\".format(dtype, dtype, str(threadid))\n    elif class_type == 'human':\n        npy_name = \"{}/{}Set{}-traj-h.npy\".format(dtype, dtype, str(threadid))\n    else:\n        npy_name = \"{}/{}Set{}-traj.npy\".format(dtype, dtype, str(threadid))\n\n    name = npy_name\n    np.save(output_dir.format(name), np.array([traj]))\n    name = \"{}/{}Set{}-track.npy\".format(dtype, dtype, str(threadid))\n    np.save(output_dir.format(name), np.array([track]))\n    \n    print(\"{} file in thread {} is saved and ready.\".format(dtype, threadid))\n\n    return len(traj)\n\ndef merge_n_split(file_names, output_dir):\n\n    output_dir = output_dir + '/{}'\n    traj_train = np.array([])\n    traj_val = np.array([])\n    traj_test = np.array([])\n\n    track_train = defaultdict(dict)\n    track_val = defaultdict(dict)\n    track_test = defaultdict(dict)\n\n    print(\"Start spliting data...\")\n\n    for f in file_names:\n        # print(\"Reading dataset {}...\".format(d))\n        npy_path = f\n        # print(npy_path)\n        data = np.load(npy_path, allow_pickle=True)\n\n        # constructing train, val and testset for trajectory\n        traj = data[0]\n        traj_id = np.unique(traj[:,1])\n        d = int(traj[0,0])\n\n        # split the dataset using vehicle id\n        traj_id, test_id = train_test_split(traj_id, test_size=0.2, random_state=0)\n        train_id, val_id = train_test_split(traj_id, test_size=0.125, random_state=0)\n\n        # get trajectory with vehicle id\n        train = np.array(traj[ [(s in train_id) for s in traj[:,1]] ])\n        if traj_train.size == 0:\n            traj_train = train\n        else:\n            traj_train = np.concatenate((traj_train, train), axis=0)\n\n        val = np.array(traj[ [(s in val_id) for s in traj[:,1]] ])\n        if traj_val.size == 0:\n            traj_val = val\n        else:\n            traj_val = np.concatenate((traj_val, val), axis=0)\n\n        test = np.array(traj[ [(s in test_id) for s in traj[:,1]] ])\n        if traj_test.size == 0:\n            traj_test = test\n        else:\n            traj_test = np.concatenate((traj_test, test), axis=0)\n\n\n        # constructing train, val and testset for tracks\n        track = data[1]\n        for i in train_id:\n            track_train[d][i] = track[i]\n\n        for i in val_id:\n            track_val[d][i] = track[i]\n\n        for i in test_id:\n            track_test[d][i] = track[i]     \n\n        print(\"Dataset {} finsihed.\".format(d))\n\n\n\n    if not os.path.exists(output_dir.format(\"train\")):\n        os.makedirs(output_dir.format(\"train\"))\n\n    f = open(output_dir.format(\"train/TrainSet.txt\"), 'w')\n    for line in traj_train:\n        # f.write(\"{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4]))\n        f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4], int(line[0])))\n    f.close()\n\n    if not os.path.exists(output_dir.format(\"val\")):\n        os.makedirs(output_dir.format(\"val\"))\n\n    f = open(output_dir.format(\"val/ValSet.txt\"), 'w')\n    for line in traj_val:\n        # f.write(\"{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4]))\n        f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4], int(line[0])))\n    f.close()\n\n    if not os.path.exists(output_dir.format(\"test\")):\n        os.makedirs(output_dir.format(\"test\"))    \n\n    f = open(output_dir.format(\"test/TestSet.txt\"), 'w')\n    for line in traj_test:\n        # f.write(\"{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4]))\n        f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(int(line[2]), int(line[1]), line[3], line[4], int(line[0])))\n    f.close()\n\n    np.save(output_dir.format(\"TrainSet.npy\"), np.array([traj_train, track_train]))\n    np.save(output_dir.format(\"ValSet.npy\"), np.array([traj_val, track_val])) \n    np.save(output_dir.format(\"TestSet.npy\"), np.array([traj_test, track_test]))\n    print(\"Training file saved and ready.\")\n\n    # print(traj_train)\n    # print(traj_val)\n    # print(traj_test)\n    # print(len(traj_train))\n    # print(len(traj_val))\n    # print(len(traj_test))\n    # for d in \n    # print(len(traj_train))\n    # print(len(traj_val))\n    # print(len(traj_test))\n    # print(traj_val)\n\n\ndef filter_edge_cases(traj, track): \n    size = np.shape(traj)[0]\n    idx = np.zeros((size, 1))\n\n    for k in range(size):\n        t = traj[k,2]\n\n        if np.shape(track[traj[k,1]])[1] > 30 and track[traj[k,1]][0, 30] < t and track[traj[k,1]][0,-1] > t+1:\n            idx[k] = 1       \n\n    return traj[np.where(idx == 1)[0],:]\n\n\n\n\ndef px_to_ft(traj, homography_dir):\n\n    m_to_ft = 3.28084\n    h = np.loadtxt(homography_dir, delimiter=' ')\n    c_x = 1280/2\n    c_y = 720/2\n\n    traj[:,3] = traj[:,3] - c_x\n    traj[:,4] = traj[:,4] - c_y\n    traj[:,3:5] = multiply_homography(h, traj[:,3:5]) * m_to_ft\n    print(\"Finish converting pixel to feet\")\n    return traj\n\ndef multiply_homography(h, pt_in):\n    # a = np.transpose(pt_in)\n    # b = np.ones((1, np.shape(pt_in)[0]))\n    # print(np.concatenate((a,b)))\n    pt = np.matmul(h, np.concatenate((np.transpose(pt_in), np.ones((1, np.shape(pt_in)[0])))))\n    pt = np.transpose(pt[0:2,:])\n    # print(pt)\n    return pt\n\ndef transform(file_dir, homography_dir, out_dir, class_type):\n    #transform(formated_txt_file_dir, None, formated_npy file_dir)\n    read = np.loadtxt(file_dir, delimiter=',')\n    traj = np.zeros((np.shape(read)[0], 47))\n    traj[:,:5] = read[:,:5]\n    \n    # uniq_id = np.unique(traj)\n    ############ preprocess ##################\n    read[read[:,5]==2,5]=1# only vehicle\n    read_v = read[read[:,5]==1]\n    traj_v = np.zeros((np.shape(read_v)[0], 47))\n    traj_v[:,:5] = read_v[:,:5]\n\n    read_b = read[read[:,5]==4]# only bike/motorcycle\n    traj_b = np.zeros((np.shape(read_b)[0], 47))\n    traj_b[:,:5] = read_b[:,:5]\n    \n    read_h = read[read[:,5]==3]# only human\n    traj_h = np.zeros((np.shape(read_h)[0], 47))\n    traj_h[:,:5] = read_h[:,:5]\n    \n    traj_class = None\n    if class_type == 'vehicle':\n        traj_class = traj_v\n    elif class_type == 'bike/motor':\n        traj_class = traj_b\n    elif class_type == 'human':\n        traj_class = traj_h\n    else:# for all\n        traj_class = traj\n    \n\n    # for k in range(np.shape(traj)[0]):#Ben: each row index(k)\n    for k in range(np.shape(traj_class)[0]):#Ben: each row index(k)\n        # print(\"Progress: {}/{} ...\".format((k+1), np.shape(traj)[0]))\n        dsid = traj_class[k][0]#traj_v\n        vehid = traj_class[k][1]#traj_v\n        time = traj_class[k][2]#traj_v\n        \n        #Get observed vehicle's trajectory\n        vehtraj = traj_class[traj_class[:,1] == vehid]\n        \n        #Get all rows which are in the same frame\n        frameEgo = traj[traj[:,2] == time]\n        \n        ''' Get Features '''\n        if frameEgo.size != 0:#In one frame, there are a lot of dynamic obstacles\n            dx = np.zeros(np.shape(frameEgo)[0])\n            dy = np.zeros(np.shape(frameEgo)[0])\n            vid = np.zeros(np.shape(frameEgo)[0])\n            \n            # agent_i를 기준으로 같은 frame 내의 object들과의 dx, dy 구하기.\n            for l in range(np.shape(frameEgo)[0]):\n                dx[l] = frameEgo[l][3] - traj_class[k][3]#traj_v\n                dy[l] = frameEgo[l][4] - traj_class[k][4]\n                vid[l] = frameEgo[l][1]\n            dist = dx*dx + dy*dy# Get the distance between others from that vehicle;\n            \n            lim = 39# maximum 39 dynamic obstacles only\n\n            if len(dist) > lim:\n                idx = np.argsort(dist)\n                # print(idx)\n                dx = np.array([dx[i] for i in idx[:lim]])\n                dy = np.array([dy[i] for i in idx[:lim]])\n                vid = np.array([vid[i] for i in idx[:lim]])\n\n            # left\n            xl = dx[dx < 0]\n            yl = dy[dx < 0]\n            vidl = vid[dx < 0]\n\n            yl_top = yl[yl>=0]\n            yl_bot = yl[yl<0]\n            vidl_top = vidl[yl>=0]#index\n            vidl_bot = vidl[yl<0]\n\n            # center\n            xc = dx[dx >= 0]\n            yc = dy[dx >= 0]\n            vidc = vid[dx >= 0]\n            yc = yc[xc < 200]\n            vidc = vidc[xc < 200]\n            xc = xc[xc < 200]\n\n            yc_top = yc[yc>=0]\n            yc_bot = yc[yc<0]\n            vidc_top = vidc[yc>=0]\n            vidc_bot = vidc[yc<0]\n\n            # right\n            xr = dx[dx >= 200]\n            yr = dy[dx >= 200]\n            vidr = vid[dx >= 200]\n\n            yr_top = yr[yr>=0]\n            yr_bot = yr[yr<0]\n            vidr_top = vidr[yr>=0]\n            vidr_bot = vidr[yr<0]\n\n\n            # parameters\n            mini_top = 7\n            mini_bot = 6\n\n            # left top\n            iy = np.argsort(yl_top)\n            iy = iy[0:min(mini_top, len(yl_top))]# 최대 6개의 좌측에 존재하는 장애물을 고려.\n            yl_top = np.array([yl_top[i] for i in iy])\n            vidl_top = np.array([vidl_top[i] for i in iy])\n            # left bottom\n            iy = np.argsort(yl_bot)\n            iy = np.array(list(reversed(iy)))\n            iy = iy[0:min(mini_bot, len(yl_bot))]\n            yl_bot = np.array([yl_bot[i] for i in iy])\n            vidl_bot = np.array([vidl_bot[i] for i in iy])\n\n            # center top\n            iy = np.argsort(yc_top)\n            iy = iy[0:min(mini_top, len(yc_top))]\n            yc_top = np.array([yc_top[i] for i in iy])\n            vidc_top = np.array([vidc_top[i] for i in iy])\n            # center bottom\n            iy = np.argsort(yc_bot)\n            iy = np.array(list(reversed(iy)))\n            iy = iy[0:min(mini_bot, len(yc_bot))]\n            yc_bot = np.array([yc_bot[i] for i in iy])\n            vidc_bot = np.array([vidc_bot[i] for i in iy])\n\n            # right top\n            iy = np.argsort(yr_top)\n            iy = iy[0:min(mini_top, len(yr_top))]\n            yr_top = np.array([yr_top[i] for i in iy])\n            vidr_top = np.array([vidr_top[i] for i in iy])\n            # right bottom\n            iy = np.argsort(yr_bot)\n            iy = np.array(list(reversed(iy)))\n            iy = iy[0:min(mini_bot, len(yr_bot))]\n            yr_bot = np.array([yr_bot[i] for i in iy])\n            vidr_bot = np.array([vidr_bot[i] for i in iy])\n\n\n            #traj_v\n            traj_class[k,8:14] = np.concatenate((np.zeros(6 - len(vidl_bot)),vidl_bot))#object_i의 left bottom에 위치한 다른 object들의 id 정보.\n            traj_class[k,14:21] = np.concatenate((vidl_top ,np.zeros(7 - len(vidl_top))))#left top\n            traj_class[k,21:27] = np.concatenate((np.zeros(6 - len(vidc_bot)),vidc_bot))#center bottom\n            traj_class[k,27:34] = np.concatenate((vidc_top ,np.zeros(7 - len(vidc_top))))#center top\n            traj_class[k,34:40] = np.concatenate((np.zeros(6 - len(vidr_bot)),vidr_bot))#right bottom\n            traj_class[k,40:47] =np.concatenate((vidr_top ,np.zeros(7 - len(vidr_top))))#right top\n\n    # convert from pixel to feet\n\n    if homography_dir:#None\n        traj = px_to_ft(traj, homography_dir)\n\n\n    # create track\n    ids = np.unique(traj[:,1])# Get all vehicle's id\n    track = {} \n    for i in range(len(ids)):\n        vtrack = traj[traj[:,1] == ids[i]]# get all row for 'ids[i]'\n        track[ids[i]] = vtrack[:,2:5].T # get (t, x, y)\n\n\n    # np.save(out_dir, np.array([traj, track]))\n    np.save(out_dir, np.array([traj_class, track, traj]))\n\n    # transfrom의 output\n    '''\n    traj  =  dsId.txt 파일과 같은 크기의 row. 각 row마다 [ dsId, object id(i), frame, x, y, i의 주변 39개까지의 주변 장애물과의 위치 관계]\n    track =  dsId.txt 파일에 존재하는 obejct(i)의 trajectory {object_id(i): [ [frame_1, x_1, y_1], [frame_2, x_2, y_2], ... [frame_p, x_p, y_p]  ]}\n    '''\n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.734594Z","iopub.execute_input":"2024-04-22T05:36:08.734903Z","iopub.status.idle":"2024-04-22T05:36:08.805006Z","shell.execute_reply.started":"2024-04-22T05:36:08.734880Z","shell.execute_reply":"2024-04-22T05:36:08.804002Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#model/model.py\nimport re\nimport os\nimport subprocess\nimport torch\nimport argparse\n\n\n# from model.Prediction.traphic import traphicNet\n# from model.Prediction.social import highwayNet\n# from model.Prediction.utils import ngsimDataset\n# from model.Prediction.traphicEngine import TraphicEngine\n# from model.Prediction.socialEngine import SocialEngine\nfrom torch.utils.data import DataLoader\nimport datetime\n\n\n\n\nclass TnpModel:\n\n    def __init__(self, inArgs):\n        torch.manual_seed(inArgs['dsId'])#seed becomes 'dataset Id'\n        torch.cuda.manual_seed(inArgs['dsId'])\n\n        self.args = {}\n        self.args[\"batch_size\"] = inArgs[\"batch_size\"]\n        self.args[\"pretrainEpochs\"] = inArgs[\"pretrainEpochs\"]\n        self.args[\"trainEpochs\"] = inArgs[\"trainEpochs\"]\n        self.args['cuda'] = inArgs[\"cuda\"]\n        self.args['device'] = inArgs['device']\n        self.args['modelLoc'] = inArgs['modelLoc']#Ben: the location of 'trained model'\n        self.args[\"optim\"] = inArgs[\"optim\"]\n\n        # Network Arguments\n        self.args['dropout_prob'] = inArgs[\"dropout\"]\n        self.args['encoder_size'] = 64\n        self.args['decoder_size'] = 128\n        self.args['in_length'] = inArgs['input_size']#Ben: INPUT (history length)\n        self.args['out_length'] = inArgs['output_size']#Ben: OUTPUT (output seq length)\n        self.args['grid_size'] = (13,3)\n        self.args['upp_grid_size'] = (7,3)\n        self.args['soc_conv_depth'] = 64\n        self.args['conv_3x1_depth'] = 16\n        self.args['dyn_embedding_size'] = 32\n        self.args['input_embedding_size'] = 32\n        self.args['num_lat_classes'] = 3\n        self.args['num_lon_classes'] = 2\n        self.args['use_maneuvers'] = inArgs[\"maneuvers\"]\n        self.args['ours'] = (inArgs[\"predAlgo\"] == \"Traphic\")\n        self.args['nll_only'] = inArgs['nll_only']\n        self.args[\"learning_rate\"] = inArgs[\"lr\"]\n        self.args[\"predAlgo\"] = inArgs[\"predAlgo\"]#TraPHic\n        self.args[\"w_decay\"] = inArgs['w_decay']\n        \n        # currentDT = datetime.datetime.now()\n        # self.args['name'] = \"{}_{}_model.tar\".format(inArgs[\"predAlgo\"], currentDT.strftime(\"%Y_%m_%d_%H_%M\"))\n        self.args['name'] = inArgs['name_temp'].format(self.args[\"predAlgo\"], inArgs['dset'])\n        self.args[\"pretrain_loss\"] = inArgs['pretrain_loss']\n        self.args['train_loss'] = inArgs['train_loss']\n        self.args['dir'] = inArgs['dir']\n        self.args['raw_dir'] = inArgs['raw_dir']\n        self.args['dsId'] = inArgs['dsId']\n        self.args['log_dir'] = inArgs['log_dir']\n        self.args['tensorboard'] = inArgs['tensorboard']\n        self.args['class_type'] = inArgs['class_type']\n        if self.args[\"predAlgo\"] == \"Traphic\":# Ben: Declare the network\n            self.net = traphicNet(self.args)\n        else:\n            self.net = highwayNet(self.args)\n\n        if self.args['cuda']:\n            self.net = self.net.cuda(self.args['device'])\n        \n\n\n    def eval_one(self, dsId=None):\n        if dsId:\n            self.args['dsId'] = dsId\n\n        self.net.train_flag = False\n\n        self.net.eval()\n        d = os.path.join(self.args['modelLoc'], self.args['name'])\n\n        if os.path.exists(d):\n            self.net.load_state_dict(torch.load(d))\n            print(\"\\n[INFO]: model {} loaded\".format(d))\n        else:\n            print(\"\\n[INFO]: can not find model at {} to evaluate, using existing net\".format(d))\n\n        if self.args[\"cuda\"]:\n            self.net.cuda(self.args['device'])\n\n\n\n        if self.args[\"optim\"] == \"Adam\":\n            optim = torch.optim.Adam(self.net.parameters(),lr=self.args['learning_rate'],weight_decay=self.args[\"w_decay\"])\n        elif self.args[\"optim\"] == \"SGD\":\n            optim = torch.optim.SGD(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"AdamW\":\n            optim = torch.optim.AdamW(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"SparseAdam\":\n            optim = torch.optim.SparseAdam(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"Adamax\":\n            optim = torch.optim.Adamax(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"ASGD\":\n            optim = torch.optim.ASGD(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"Rprop\":\n            optim = torch.optim.Rprop(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"RMSprop\":\n            optim = torch.optim.RMSprop(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"LBFGS\":\n            optim = torch.optim.LBFGS(self.net.parameters(),lr=self.args['learning_rate'])\n        else:\n            print(\"undefined optimizer.\")\n            return\n\n        crossEnt = torch.nn.BCELoss()\n        self.net()\n\n    def load(self, d=None, load=False):\n        self.net.eval()#Ben: model.eval() will notify all your layers that you are in eval mode, \n                       #     that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n        if not d:#Ben: Get a location(path)\n            d = os.path.join(self.args['modelLoc'], self.args['name'])\n        else:\n            if load:\n                self.args['name'] = d \n            d = os.path.join(self.args['modelLoc'], d)\n        \n        if os.path.exists(d):\n            self.net.load_state_dict(torch.load(d))\n            print(\"\\n[INFO]: model {} loaded\\n\".format(d))\n        else:\n            print(\"\\n[INFO]: can not find model at {} to evaluate, using existing net\".format(d))\n\n\n    def train(self, dsId=None):\n        if dsId:\n            self.args['dsId'] = dsId\n    \n        self.net.train_flag = True\n        self.net.train()\n        if self.args[\"cuda\"]:\n            self.net.cuda(self.args['device'])\n\n        if self.args[\"optim\"] == \"Adam\":\n            optim = torch.optim.Adam(self.net.parameters(),lr=self.args['learning_rate'],weight_decay=self.args[\"w_decay\"])\n        elif self.args[\"optim\"] == \"SGD\":\n            optim = torch.optim.SGD(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"AdamW\":\n            optim = torch.optim.AdamW(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"SparseAdam\":\n            optim = torch.optim.SparseAdam(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"Adamax\":\n            optim = torch.optim.Adamax(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"ASGD\":\n            optim = torch.optim.ASGD(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"Rprop\":\n            optim = torch.optim.Rprop(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"RMSprop\":\n            optim = torch.optim.RMSprop(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"LBFGS\":\n            optim = torch.optim.LBFGS(self.net.parameters(),lr=self.args['learning_rate'])\n        else:\n            print(\"undefined optimizer.\")\n            return\n\n        crossEnt = torch.nn.BCELoss()#ben: Binary Cross Entrophy\n\n        print('loading data in {}...'.format(self.args['dsId']))\n        trSet_path = os.path.join(self.args[\"dir\"], \"trainSet\")\n        valSet_path = os.path.join(self.args[\"dir\"], \"valSet\")\n        \n        trSet = ngsimDataset(trSet_path, self.args[\"dir\"], self.args[\"raw_dir\"], 'train', self.args['dsId'], self.args['class_type'], t_h=self.args['in_length'], t_f=self.args['out_length'])\n        valSet = ngsimDataset(valSet_path, self.args[\"dir\"], self.args[\"raw_dir\"], 'val', self.args['dsId'], self.args['class_type'], t_h=self.args['in_length'], t_f=self.args['out_length'])\n\n        trDataloader = DataLoader(trSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=trSet.collate_fn)\n        # trDataloader = DataLoader(valSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=valSet.collate_fn)\n        valDataloader = DataLoader(valSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=valSet.collate_fn)\n        \n        print(\"==================Attribute===========\")\n        sample = trSet[0]  # Get the first sample\n        num_attributes = len(sample)  # Get the number of attributes in the sample\n\n        print(\"Number of Attribute\")\n        print(num_attributes)\n        print(\"==================Attribute===========\")\n        \n        \n        print('start training {}...'.format(self.args[\"predAlgo\"]))\n        if self.args[\"predAlgo\"] == \"Traphic\":\n            engine = TraphicEngine(self.net, optim, trDataloader, valDataloader, self.args)\n        else:\n            engine = SocialEngine(self.net, optim, trDataloader, valDataloader, self.args)\n\n        engine.start()\n\n\n        \n\n    def evaluate(self, dsId=None):\n        if dsId:# Ben: dataset id?? TODO\n            self.args['dsId'] = dsId\n\n        self.net.train_flag = False\n        self.net.eval()# Ben: Ready for evaluation\n        d = os.path.join(self.args['modelLoc'], self.args['name'])\n\n        if os.path.exists(d):\n            self.net.load_state_dict(torch.load(d, map_location = 'cuda:0'))#Ben: error handled\n            print(\"\\n[INFO]: model {} loaded\".format(d))\n        else:\n            print(\"\\n[INFO]: can not find model at {} to evaluate, using existing net\".format(d))\n\n        if self.args[\"cuda\"]:\n            self.net.cuda(self.args['device'])\n\n\n\n        if self.args[\"optim\"] == \"Adam\":\n            optim = torch.optim.Adam(self.net.parameters(),lr=self.args['learning_rate'],weight_decay=self.args[\"w_decay\"])\n        elif self.args[\"optim\"] == \"SGD\":\n            optim = torch.optim.SGD(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"AdamW\":\n            optim = torch.optim.AdamW(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"SparseAdam\":\n            optim = torch.optim.SparseAdam(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"Adamax\":\n            optim = torch.optim.Adamax(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"ASGD\":\n            optim = torch.optim.ASGD(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"Rprop\":\n            optim = torch.optim.Rprop(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"RMSprop\":\n            optim = torch.optim.RMSprop(self.net.parameters(),lr=self.args['learning_rate'])\n        elif self.args[\"optim\"] == \"LBFGS\":\n            optim = torch.optim.LBFGS(self.net.parameters(),lr=self.args['learning_rate'])\n        else:\n            print(\"undefined optimizer.\")\n            return\n\n        crossEnt = torch.nn.BCELoss()\n\n        print('loading data in {}...'.format(self.args['dsId']))\n        trSet_path = os.path.join(self.args[\"dir\"], \"trainSet\")\n        valSet_path = os.path.join(self.args[\"dir\"], \"valSet\")\n        tstSet_path = os.path.join(self.args[\"dir\"], \"testSet\")\n\n        trSet = ngsimDataset(trSet_path, self.args[\"dir\"], self.args[\"raw_dir\"], 'train', self.args['dsId'], self.args['class_type'], t_h=self.args['in_length'], t_f=self.args['out_length'])\n        trDataloader = DataLoader(trSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=trSet.collate_fn)\n\n        testSet = ngsimDataset(valSet_path, self.args[\"dir\"], self.args[\"raw_dir\"], 'val', self.args['dsId'], self.args['class_type'], t_h=self.args['in_length'], t_f=self.args['out_length'])\n        testDataloader = DataLoader(testSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=testSet.collate_fn)\n\n        valSet = ngsimDataset(tstSet_path, self.args[\"dir\"], self.args[\"raw_dir\"], 'val', self.args['dsId'], self.args['class_type'], t_h=self.args['in_length'], t_f=self.args['out_length'])\n        valDataloader = DataLoader(valSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=valSet.collate_fn)\n\n        print('start testing {}...'.format(self.args[\"predAlgo\"]))\n        if self.args[\"predAlgo\"] == \"Traphic\":\n            engine = TraphicEngine(self.net, optim, trDataloader, valDataloader, self.args)\n        else:\n            engine = SocialEngine(self.net, optim, trDataloader, valDataloader, self.args)\n\n        engine.eval(trDataloader)\n        # engine.eval(testDataloader)\n\n    def result_viz(self):#TODO\n        # This function is for visualizing the network output and ground truth trajectory\n        # print('loading data in {}...'.format(self.args['dsId']))\n        tstSet_path = os.path.join(self.args[\"dir\"], \"testSet\")\n\n        testSet = ngsimDataset(valSet_path, self.args[\"dir\"], self.args[\"raw_dir\"], 'val', self.args['dsId'], t_h=self.args['in_length'], t_f=self.args['out_length'])\n        testDataloader = DataLoader(testSet,batch_size=self.args['batch_size'],shuffle=True,num_workers=4,collate_fn=testSet.collate_fn)\n        if self.args[\"predAlgo\"] == \"Traphic\":\n            engine = TraphicEngine(self.net, optim, trDataloader, valDataloader, self.args)\n        else:\n            engine = SocialEngine(self.net, optim, trDataloader, valDataloader, self.args)\n        \n\nprint(\"Execute done\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.808085Z","iopub.execute_input":"2024-04-22T05:36:08.808662Z","iopub.status.idle":"2024-04-22T05:36:08.869787Z","shell.execute_reply.started":"2024-04-22T05:36:08.808633Z","shell.execute_reply":"2024-04-22T05:36:08.868782Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Execute done\n","output_type":"stream"}]},{"cell_type":"code","source":"#traphic_main.py\nimport argparse\nimport warnings\nimport re\nimport os\nimport csv\n# from model.model import TnpModel\n# from model.import_data import *\nimport time\n\nwarnings.filterwarnings(\"ignore\")\n\n'''     IMPORTANT     '''\n\nDATASET = 'APOL'# Use Apolloscape dataset\nLOG = '/kaggle/working/logs/'\nLOAD = ''# Load the trained model\n\nCUDA = True \nDEVICE = 'cuda:0'\n\nPREDALGO = 'Traphic'\n# PREDALGO = 'Highway'\n\nPRETRAINEPOCHS= 0# Untill pretrained epoch\nTRAINEPOCHS= 10# After pretrained epoch\nINPUT = 6 #Trajectory sequence input\nOUTPUT = 10#Trajectory sequence output for prediction\nMANUAL_SEED = 42\nTENSORBOARD = True#For using tensorboard\n\nDATA_DIR = '/kaggle/input/apoldata/data/' + DATASET\nMODELLOC = \"/kaggle/working/TRAPHIC_weight/\"\nRAW_DATA = \"/kaggle/input/apoldata/data/prediction_train/\"\n\nTRAIN = True\nEVAL = True\n\n# training option \t\t\t\t========== Hyper-parameter ==========\nBATCH_SIZE = 32\nDROPOUT = 0.5\nOPTIM= 'Adam'\n# SGD Adam AdamW SparseAdam Adamax ASGD RMSprop Rprop \nLEARNING_RATE= 0.001\nMANEUVERS = False#Ben: TODO\nPRETRAIN_LOSS = 'NLL'# Negative Log-Likelihood\nTRAIN_LOSS = 'MSE'\nNLL_ONLY = True\nWEIGHT_DECAY = 1e-4\n# Trained model name for saving\nNAME = '{}.{}' + '.model_{}-{}l_{}epochs.seed{}.batch{}.nll_only.{}.tar'\\\n\t\t\t.format(INPUT, OUTPUT, PRETRAINEPOCHS + TRAINEPOCHS, MANUAL_SEED, BATCH_SIZE, NLL_ONLY)\n\nGENERATE_DATASET = False\n# If you want to generate a model for considering vehicle' only, \"CLASS_TYPE = 'vehicle'\",\n# For any other class, there are {'bike/motor', 'human'}. For considering all class, just use 'all'\nCLASS_TYPE = 'all' #(vehicle, 'bike/motor', 'human', 'all')\n\ndef apol_to_formatted(input_dir, files, output_dir, dtype):\n\ttxtlst = []\n\ti = 0 \n\tsz = len(files)\n\tprint(\"=======================================\")\n\tfor f in files:\n\t\tprint(\"Processing {}/{} in {}...\".format(i, sz, dtype))\n\t\t# print(\"files: \", f)\n\t\ti += 1\n\t\tsplitted_name = f.split('_')\n\t\tdset_id = splitted_name[1] + splitted_name[2].zfill(2)#for prediction_train,test.zip\n\t\t\n\t\tout_name = dset_id + '.txt'\n\t\ttxtlst.append(dset_id)\n\t\t\n\t\tcurrent_time = -1\n\t\tcurrent_frame_num = -1\n\n\t\tif not os.path.exists(output_dir):\n\t\t\tos.mkdir(output_dir)\n\n\t\tout = open(os.path.join(output_dir, out_name), 'w')\n\t\tf = os.path.join(input_dir, f)\n\n\t\twith open(f) as csv_file:\n\t\t\tfor row in csv.reader(csv_file):\n\t\n\t\t\t\teach_row = row[0].split(' ')\n\t\t\t\tcurrent_frame_num = each_row[0]\n\t\t\t\tvid_type = each_row[2]\n            \n\t\t\t\tvid = int(each_row[1].split('-')[-1])\n\t\t\t\tout.write(\"{},{},{},{},{},{}\\n\".format(float(dset_id), vid, current_frame_num, each_row[3], each_row[4], vid_type))\n\treturn txtlst\n\ndef create_data(input_dir, file_names, output_dir, dtype, threadid, class_type):\n\tname_lst = []\n\ti = 0\n\tsz = len(file_names)\n\tfor f in file_names:\n\t\tprint(\"Importing data {}/{} for {} in thread {}...\".format(i, sz, dtype, threadid))\n\t\ti += 1\n\t\tdset_id = f\n\t\t\n\t\tloc = os.path.join(input_dir,dset_id+'.txt')#from 'formated folder'; i.e. formated txt file\n\t\tout = os.path.join(input_dir,dset_id+'.npy')\n\t\timport_data(loc, None, out, class_type)\n\t\tname_lst.append(out)\n\t\n\tmerge(name_lst, output_dir, dtype, threadid, class_type)\n\tprint('\"merge\" is finished!')\n\n\n\nif __name__ == \"__main__\":\n\n\tparser = argparse.ArgumentParser(description=\"traphicPred command line control\")\n\n\tparser.add_argument('--cuda', '-g', action='store_true', help='GPU option', default=CUDA)\n\tparser.add_argument('--device', '-d', help='cuda device option', default=DEVICE, type=str)\n\n\tparser.add_argument('--batch_size', '-b', help='bastch size', default=BATCH_SIZE)\n\tparser.add_argument('--dropout', help='dropout probability', default=DROPOUT)\n\tparser.add_argument('--lr', help='learning rate', default=LEARNING_RATE)\n\tparser.add_argument('--optim', help='optimiser', default=OPTIM)\n\tparser.add_argument('--w_decay', help='weight decay rate', default=WEIGHT_DECAY)\n\tparser.add_argument('--pretrainEpochs', '-p', help='number of epochs for pretraining', default=PRETRAINEPOCHS, type=int)\n\tparser.add_argument('--trainEpochs', '-e', help='number of epochs for training', default=TRAINEPOCHS, type=int)\n\tparser.add_argument('--maneuvers', help='maneuvers option', default=MANEUVERS, type=bool)\n\tparser.add_argument('--predalgo', help='prediction algorithm', default=PREDALGO)#TraPHic\n\tparser.add_argument('--pretrain_loss', help='pretrain loss algorithm', default=PRETRAIN_LOSS)\n\tparser.add_argument('--train_loss', help='train loss algorithm', default=TRAIN_LOSS)\n\n\tparser.add_argument('--dset', '-s', help='cuda device option', default=DATASET, type=str)\n\tparser.add_argument('--modelLoc', help='trained prediction store/load location', default=MODELLOC)\n\tparser.add_argument('--dir', help=\"location of the dataset for tracking\", default=DATA_DIR)\n\tparser.add_argument(\"-f\", required=False)\n\n\targs, unknown = parser.parse_known_args()\n\n\n\n\tviewArgs = {}\n\tviewArgs['cuda'] = args.cuda\n\tviewArgs['log_dir'] = LOG\n\tviewArgs['batch_size'] = args.batch_size\n\tviewArgs['dropout'] = args.dropout\n\tviewArgs[\"lr\"] = args.lr\n\tviewArgs[\"optim\"] = args.optim\n\tviewArgs['w_decay'] = args.w_decay\n\tviewArgs['pretrainEpochs'] = args.pretrainEpochs\n\tviewArgs['trainEpochs'] = args.trainEpochs\n\tviewArgs[\"maneuvers\"] = args.maneuvers\n\tviewArgs['predAlgo'] = args.predalgo\n\tviewArgs['pretrain_loss'] = args.pretrain_loss\n\tviewArgs['train_loss'] = args.train_loss\n\tviewArgs['nll_only'] = NLL_ONLY\n\tviewArgs['tensorboard'] = TENSORBOARD\n\n\tviewArgs['modelLoc'] = args.modelLoc\n\tviewArgs['dir'] = args.dir\n\tviewArgs['raw_dir'] = RAW_DATA\n\tif not args.cuda:\n\t\targs.device = 'cpu'\n\tviewArgs['device'] = args.device\n\n\tviewArgs['dsId'] = MANUAL_SEED# It represents seed number, which means each different seed generates different (train, val, test) set\n\tviewArgs['dset'] = args.dset\n\tviewArgs['name_temp'] = NAME\n\tviewArgs['input_size'] = INPUT\n\tviewArgs['output_size'] = OUTPUT\n\tviewArgs['class_type'] = CLASS_TYPE\n\t\n\tif GENERATE_DATASET:\n\t\t''' dataset ratio --> (train, val, test)==(0.7, 0.2, 0.1) '''\n\t\tnp.random.seed(MANUAL_SEED)\n\t\tthreadid = MANUAL_SEED\n\t\tclass_type = CLASS_TYPE\n\t\tfiles = None\n\n\t\traw_data = os.listdir(RAW_DATA)\n\t\tget_all_txtfile = [f for f in raw_data if '.txt' in f]\n\t\tdataset_cnt = len(get_all_txtfile)# Ben: Get the number of all data in 'data_dirs'\n\t\tdatasets_dir = sorted(get_all_txtfile)\n\t\tnp.random.shuffle(datasets_dir)\n\t\n\t\tdatasets_for_train = datasets_dir[:int(dataset_cnt * 0.7)]\n\t\tdatasets_for_val = datasets_dir[int(dataset_cnt * 0.7):int(dataset_cnt * 0.9)]\n\t\tdatasets_for_test = datasets_dir[int(dataset_cnt * 0.9) :]\n\t\t\n\t\tprint('dataset is generated...')\n\t\ttrain_loc = RAW_DATA\n\t\toutput_dir = RAW_DATA + '/train/formatted/'\n\t\tfiles = datasets_for_train\n\t\ttrain_lst = apol_to_formatted(train_loc, files, output_dir, \"train\")\n\t\tcreate_data(output_dir, train_lst, args.dir, \"train\", threadid, class_type)\n\n\t\tval_loc = RAW_DATA\n\t\toutput_dir = RAW_DATA + '/val/formatted/'\n\t\tfiles = datasets_for_val\n\t\tval_lst = apol_to_formatted(val_loc, files, output_dir, \"val\")\n\t\tcreate_data(output_dir, val_lst, args.dir, \"val\", threadid, class_type)\n\n\t\ttest_loc = RAW_DATA\n\t\toutput_dir = RAW_DATA + '/test_obs/formatted/'\n\t\tfiles = datasets_for_test\n\t\ttest_lst = apol_to_formatted(test_loc, files, output_dir, \"test\")\n\t\tcreate_data(output_dir, test_lst, args.dir, \"test\", threadid, class_type)\n\n\t\tquit()\n\tprint('using {} dataset.'.format(DATASET))\n\n\tt0 = time.time()#ben: initialize time\n\n\tmodel = TnpModel(viewArgs)\n\tif args.cuda:\n\t\tprint(\"using cuda...\\n\")\n\telse:\n\t\tprint(\"using cpu...\\n\")\n\n\tif LOAD != '':\n\t\tmodel.load(LOAD)\n\t\tprint(\"===================Load Model===========\")\n        \n\tt1 = time.time()\n\n\tif TRAIN:\n\t\tmodel.train(viewArgs['dsId'])\n\n\tt2 = time.time()\n\n\tif EVAL:\n\t\tmodel.evaluate()\n\n\tt3 = time.time()\n\n\tprint('\\nusing {} dataset.'.format(DATASET))\n\t\n\tprint('Loading time:{}'.format(t1 - t0))\n\tprint(\"Training time:{}\".format(t2 - t1))\n\tprint(\"Testing time:{}\".format(t3 - t2))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T05:36:08.871183Z","iopub.execute_input":"2024-04-22T05:36:08.871552Z","iopub.status.idle":"2024-04-22T05:36:47.168191Z","shell.execute_reply.started":"2024-04-22T05:36:08.871521Z","shell.execute_reply":"2024-04-22T05:36:47.166727Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"using APOL dataset.\n===================Execute Model Iitialization===========\nusing cuda...\n\nloading data in 42...\nload train dataset\ndtype is train and dset(manual_seed) is 42\nThe size of TRAJ file:  49232\nThe size of TRACK file:  37\nload val dataset\ndtype is val and dset(manual_seed) is 42\nThe size of TRAJ file:  13658\nThe size of TRACK file:  10\n==================Attribute===========\nNumber of Attribute\n10\n==================Attribute===========\nstart training Traphic...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[1/1539]   0%|          , Avg train loss=4.65e+3, Avg val loss=0 [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ceef3caac94036b7a2f28249333edb"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 226\u001b[0m\n\u001b[1;32m    223\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[0;32m--> 226\u001b[0m \t\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mviewArgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdsId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m EVAL:\n","Cell \u001b[0;32mIn[21], line 198\u001b[0m, in \u001b[0;36mTnpModel.train\u001b[0;34m(self, dsId)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     engine \u001b[38;5;241m=\u001b[39m SocialEngine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet, optim, trDataloader, valDataloader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m--> 198\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 254\u001b[0m, in \u001b[0;36mTrajPredEngine.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput, engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39miteration)\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m#    if iter % 10 == 0:\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m#         print(\"============Running============\")\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# if not self.eval_only:\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;66;03m# self.trainer.run(self.train_loader, max_epochs=1)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensorboard:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ignite/engine/engine.py:1033\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mGET_BATCH_STARTED)\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# We should not trigger GET_BATCH_STARTED, GET_BATCH_COMPLETED, DATALOADER_STOP_ITERATION events\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m# if no data was provided to engine.run(data=None, ...)\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}